{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_openai.chat_models.base import BaseChatOpenAI\n",
    "\n",
    "from typing import Sequence, Callable, Any\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "ANTHROPIC_API_KEY=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_openai = ChatOpenAI(model=\"gpt-4o-mini\", max_completion_tokens=100)\n",
    "model_anthropic = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "model_deepseek = BaseChatOpenAI(model=\"deepseek-chat\",\n",
    "                                openai_api_key=DEEPSEEK_API_KEY,\n",
    "                                openai_api_base='https://api.deepseek.com',\n",
    "                                max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Ana! It's great to meet you. The EU AI Act is a fascinating and important piece of legislation, especially for professionals like you who are navigating the intersection of law and technology. The Act aims to regulate artificial intelligence systems to ensure they are safe, transparent, and respect fundamental rights while fostering innovation.\n",
      "\n",
      "Here are some key points about the EU AI Act that might interest you:\n",
      "\n",
      "1. **Risk-Based Approach**: The Act categorizes AI systems into four levels of risk—unacceptable, high\n"
     ]
    }
   ],
   "source": [
    "response = model_deepseek.invoke(\"Hi!, I'm Ana. I'm a lawyer and I'm interested in the EU AI Act.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    prompt_template: ChatPromptTemplate\n",
    "    model_used: BaseChatModel\n",
    "    language: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "import langchain\n",
    "\n",
    "langchain.cache = InMemoryCache()\n",
    "# Or for persistent caching:\n",
    "# from langchain.cache import SQLiteCache\n",
    "# langchain.cache = SQLiteCache(database_path=\".langchain.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmer(model: BaseChatModel) -> Callable[[MessagesState], list[BaseMessage]]:\n",
    "    return trim_messages(\n",
    "        max_tokens=50,\n",
    "        strategy=\"last\",\n",
    "        token_counter=model,\n",
    "        include_system=True,\n",
    "        allow_partial=True,\n",
    "        start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_first_layer_model(state: State) -> dict[str, list[BaseMessage]]:\n",
    "    trimmed_messages = trimmer(model=state[\"model_used\"]).invoke(state[\"messages\"])\n",
    "    template = state[\"prompt_template\"]\n",
    "    model = state[\"model_used\"]\n",
    "    prompt = template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state.get(\"language\", \"English\")}, config)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lawyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_lawyer = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are an experienced attorney with decades of expertise, known for your thorough understanding of legal frameworks and your ability to articulate precise, formal, and well-reasoned arguments. \"\n",
    "                \"Your goal is to provide comprehensive, professional responses that reflect a deep knowledge of the law, ethical considerations, and relevant legal principles. \"\n",
    "                \"When appropriate, reference specific statutes, regulations, case law, or precedents to support your response. For example, in U.S. law, you might cite Marbury v. Madison (1803) for judicial review, or relevant sections of the UCC for commercial disputes. \"\n",
    "                \"Structure your response logically with clear headings and subheadings if the question involves multiple aspects. Avoid assumptions beyond the given information and seek clarification if necessary. \"\n",
    "                \"Always communicate in {language}, maintaining a professional and respectful tone, ensuring accessibility for both legal experts and non-specialists. \"\n",
    "                \"Conclude your response with a summary or actionable next steps if applicable.\"\n",
    "            ),\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(\n",
    "    schema: dict[str, Any], \n",
    "    function: Callable[[State], dict[str, list[BaseMessage]]]\n",
    "):\n",
    "    workflow = StateGraph(state_schema=schema)\n",
    "    workflow.add_edge(START, \"llm_call\")\n",
    "    workflow.add_node(\"llm_call\", function)\n",
    "    return workflow.compile(checkpointer=MemorySaver())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Ana,\n",
      "\n",
      "### Introducción a la EU AI Act\n",
      "\n",
      "La **EU AI Act** (Reglamento sobre Inteligencia Artificial de la Unión Europea) es una propuesta de legislación presentada por la Comisión Europea con el objetivo de regular el desarrollo y uso de tecnologías de inteligencia artificial (IA) en la Unión Europea. Este marco jurídico busca garantizar que la IA sea utilizada de manera segura y ética, promoviendo la innovación y protegiendo los derechos fundamentales de los ciudadanos.\n",
      "\n",
      "### Objetivos Principales\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Hola, me llamo Ana. Me gustaria saber que es la EU AI Act.\"\n",
    "language = \"Spanish\"\n",
    "config = {\"configurable\": {\"thread_id\": \"aaa123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output_lawyer = create_graph(State, call_first_layer_model).invoke({\n",
    "    \"messages\": input_messages, \n",
    "    \"language\": language,\n",
    "    \"prompt_template\": prompt_template_lawyer,\n",
    "    \"model_used\": model_openai,\n",
    "    }, \n",
    "config)\n",
    "print(output_lawyer[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_social = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are a seasoned social media strategist with extensive experience in creating highly engaging and platform-specific content across Instagram, TikTok, YouTube, LinkedIn, and other major platforms. \"\n",
    "                \"Your expertise includes crafting strategies that drive audience growth, boost engagement, and optimize monetization opportunities. \"\n",
    "                \"Provide practical, actionable advice tailored to the platform in focus. For example, on Instagram, you might recommend using carousel posts for storytelling, leveraging trending Reels audio, or optimizing posting times based on analytics. \"\n",
    "                \"On TikTok, suggest ideas for viral trends, short-form video hooks, or creative hashtag usage. \"\n",
    "                \"Your recommendations should reflect the latest features and trends, such as LinkedIn’s algorithm preferences for professional storytelling or YouTube Shorts for reaching broader audiences. \"\n",
    "                \"When discussing analytics, explain how to track and interpret key metrics like engagement rates, click-through rates (CTR), or watch time, providing examples where relevant. \"\n",
    "                \"Offer community-building strategies, such as fostering meaningful interactions in comment sections or collaborating with influencers, to strengthen brand loyalty. \"\n",
    "                \"Communicate in {language}, maintaining an engaging and approachable tone suitable for both novice and experienced content creators. \"\n",
    "                \"Ensure your response includes real-world examples, practical tips, and clear steps for implementation.\"\n",
    "            ),\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola, Ana! Es genial que estés interesado en el tema de la regulación de la inteligencia artificial. A continuación, te explico cómo se están desarrollando las normativas en Estados Unidos en comparación con el EU AI Act.\n",
      "\n",
      "### Equivalente del EU AI Act en EE. UU.\n",
      "\n",
      "1. **No hay una ley federal única**: A diferencia de la Unión Europea, donde se está trabajando en un marco único (el EU AI Act) para regular la inteligencia artificial, en Estados Unidos\n"
     ]
    }
   ],
   "source": [
    "query = \"Me gustaria saber el equivalente de la EU AI Act en USA\"\n",
    "language = \"Spanish\"\n",
    "config = {\"configurable\": {\"thread_id\": \"aaa123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output_social = create_graph(State, call_first_layer_model).invoke({\n",
    "    \"messages\": input_messages, \n",
    "    \"language\": language,\n",
    "    \"prompt_template\": prompt_template_social,\n",
    "    \"model_used\": model_openai,\n",
    "    }, \n",
    "config)\n",
    "print(output_social[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizerState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    prompt_template: ChatPromptTemplate\n",
    "    model_used: BaseChatModel\n",
    "    language: str\n",
    "    output_experts: list[dict[str, list[BaseMessage]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_second_layer_model(state: SummarizerState) -> dict[str, list[BaseMessage]]:\n",
    "    trimmed_messages = trimmer(model=state[\"model_used\"]).invoke(state[\"messages\"])\n",
    "    template = state[\"prompt_template\"]\n",
    "    model = state[\"model_used\"]\n",
    "    output_experts = \"\".join([f\" Expert {i+1}: {expert['messages'][-1].content}\" for i, expert in enumerate(state[\"output_experts\"])])\n",
    "\n",
    "    prompt = template.invoke({\n",
    "        \"messages\": trimmed_messages, \n",
    "        \"language\": state.get(\"language\", \"English\"),\n",
    "        \"output_experts\": output_experts\n",
    "    }, config)\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    output_summarizer = f\"\"\"The experts have provided the following information: {output_experts}\n",
    "        The summary of the information is: {response}\n",
    "    \"\"\"\n",
    "    return {\"messages\": [output_summarizer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_summarizer = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\"\"\"\n",
    "                You are an expert summarizer with exceptional skills in synthesizing and distilling information from diverse sources.\n",
    "                Your task is to combine the key insights from the experts provided here: {output_experts}.\n",
    "                Craft a clear, concise, and cohesive summary that integrates their perspectives effectively, respecting each expert's unique focus and intent.\\n\\n\n",
    "                Specifications:\n",
    "                   - Provide a concise synthesis that integrates all perspectives.\\n\n",
    "                   - Ensure the summary is engaging, easy to understand, and tailored to the intended audience.\\n\\n\n",
    "                When summarizing:\\n\n",
    "                - Maintain a professional yet conversational tone, ensuring accessibility for readers with varying levels of expertise.\\n\n",
    "                - Use analogies, examples, or simplified explanations to enhance understanding when complex concepts are involved.\\n\n",
    "                - Format your response with bullet points, headings, or short paragraphs for readability.\\n\\n\n",
    "                Your response must be in {language} and must align with the style and context appropriate to the provided audience.\n",
    "            \"\"\"),\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The experts have provided the following information:  Expert 1: Hola Ana,\n",
      "\n",
      "### Introducción a la EU AI Act\n",
      "\n",
      "La **EU AI Act** (Reglamento sobre Inteligencia Artificial de la Unión Europea) es una propuesta de legislación presentada por la Comisión Europea con el objetivo de regular el desarrollo y uso de tecnologías de inteligencia artificial (IA) en la Unión Europea. Este marco jurídico busca garantizar que la IA sea utilizada de manera segura y ética, promoviendo la innovación y protegiendo los derechos fundamentales de los ciudadanos.\n",
      "\n",
      "### Objetivos Principales\n",
      "\n",
      " Expert 2: ¡Hola, Ana! Es genial que estés interesado en el tema de la regulación de la inteligencia artificial. A continuación, te explico cómo se están desarrollando las normativas en Estados Unidos en comparación con el EU AI Act.\n",
      "\n",
      "### Equivalente del EU AI Act en EE. UU.\n",
      "\n",
      "1. **No hay una ley federal única**: A diferencia de la Unión Europea, donde se está trabajando en un marco único (el EU AI Act) para regular la inteligencia artificial, en Estados Unidos\n",
      "        The summary of the information is: content='### Introducción a la Regulación de la IA en la UE y EE. UU.\\n\\nLa regulación de la inteligencia artificial (IA) es un tema clave en el desarrollo tecnológico actual, y distintos enfoques están siendo adoptados en la Unión Europea y Estados Unidos.\\n\\n#### EU AI Act\\n\\n- **Objetivo**: La **EU AI Act** es una propuesta legislativa presentada por la Comisión Europea diseñada para regular el uso y desarrollo de tecnologías de IA en la UE.\\n- **Enfoque' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 407, 'total_tokens': 507, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'length', 'logprobs': None} id='run-4d1c3b07-57c5-4120-ab11-92b5fa2b9836-0' usage_metadata={'input_tokens': 407, 'output_tokens': 100, 'total_tokens': 507, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "query = \"Sintetiza los inputs de los expertos\"\n",
    "language = \"Spanish\"\n",
    "config = {\"configurable\": {\"thread_id\": \"aaa124\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output_summarizer = create_graph(SummarizerState, call_second_layer_model).invoke({\n",
    "    \"messages\": input_messages, \n",
    "    \"language\": language,\n",
    "    \"prompt_template\": prompt_template_summarizer,\n",
    "    \"model_used\": model_openai,\n",
    "    \"output_experts\":[output_lawyer, output_social]\n",
    "    }, \n",
    "config)\n",
    "print(output_summarizer[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiagent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining tooling\n",
    "import json\n",
    "from typing import Annotated\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from pydantic import BaseModel\n",
    "\n",
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=2,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    k=2,  # Reduced for clarity\n",
    ")\n",
    "\n",
    "class News(TypedDict):\n",
    "    title: str\n",
    "    url: str\n",
    "    content: str\n",
    "\n",
    "class OutputResarch(BaseModel):\n",
    "    answer: str\n",
    "    news: list[News]\n",
    "\n",
    "    def news_to_string(self) -> str:\n",
    "        return ''.join([f\"Title: {new['title']}\\nURL: {new['url']}\\nContent: {new['content']}\\n\\n\" for new in self.news])\n",
    "\n",
    "\n",
    "@tool\n",
    "def legal_search_tool(\n",
    "    query: Annotated[str, \"The legal topic or question to research.\"],\n",
    ") -> OutputResarch:\n",
    "    \"\"\"Use this to search for legal information, regulations, and analysis online.\n",
    "    Particularly useful for researching specific laws, regulations, or legal frameworks.\"\"\"\n",
    "    try:\n",
    "        results = tavily_tool.invoke({\"args\": {'query': query}, \"type\": \"tool_call\", \"id\": \"foo\", \"name\": \"tavily\"})\n",
    "        \n",
    "        list_news: list[News] = []\n",
    "        for new in results.artifact.get('results'):\n",
    "            list_news.append(\n",
    "                News(\n",
    "                    title=new.get('title', 'No title'), \n",
    "                    url=new.get('url', 'No URL'), \n",
    "                    content=new.get('content', 'No content')\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        output_research = OutputResarch(\n",
    "            answer=results.artifact.get('answer', 'No answer'),\n",
    "            news=list_news\n",
    "        )\n",
    "\n",
    "        return output_research\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Failed to perform search. Error: {repr(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='The EU AI Act for high-risk AI systems mandates the use of a postmarket monitoring system to collect and review information on the performance of the AI system, allowing for immediate corrective or preventative actions if necessary. Providers must also consider existing compliance requirements, such as GDPR, as AI systems often use personal data. Additionally, companies are required to classify the risk level of their AI systems to determine regulatory obligations, with high-risk systems falling under specific categories that carry different regulatory requirements.' news=[{'title': 'Understanding the EU AI Act: Requirements and Next Steps - ISACA', 'url': 'https://www.isaca.org/resources/white-papers/2024/understanding-the-eu-ai-act', 'content': 'The EU AI Act requires that providers of high-risk AI systems use a postmarket monitoring system to collect and review information relevant to the performance of the AI system so they can identify any need to immediately apply a corrective or preventative action. Consider existing compliance requirements—AI systems and models will likely use personal data, which means that applicable privacy regulations, e.g., GDPR, can apply alongside the EU AI Act. Revise existing policies—AI systems can perform a variety of tasks, but not all use cases may be compliant with applicable laws and regulations or fall within an enterprise’s risk appetite.'}, {'title': 'A Primer on the EU AI Act - OpenAI', 'url': 'https://openai.com/global-affairs/a-primer-on-the-eu-ai-act/', 'content': 'The AI Act is built upon a risk-based framework, with specific requirements for high-risk and unacceptable-risk AI systems. The Act requires companies to classify the risk level of their AI systems to determine the corresponding regulatory obligations, and sets out various categories or tiers of AI systems that each carry different obligations.'}]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What are the main requirements of the EU AI Act for high-risk AI systems?\"\n",
    "# Use the invoke() method instead of direct call\n",
    "results = legal_search_tool.invoke(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EU AI Act for high-risk AI systems mandates the use of a postmarket monitoring system to collect and review information on the performance of the AI system, allowing for immediate corrective or preventative actions if necessary. Providers must also consider existing compliance requirements, such as GDPR, as AI systems often use personal data. Additionally, companies are required to classify the risk level of their AI systems to determine regulatory obligations, with high-risk systems falling under specific categories that carry different regulatory requirements.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Title: Understanding the EU AI Act: Requirements and Next Steps - ISACA\n",
      "URL: https://www.isaca.org/resources/white-papers/2024/understanding-the-eu-ai-act\n",
      "Content: The EU AI Act requires that providers of high-risk AI systems use a postmarket monitoring system to collect and review information relevant to the performance of the AI system so they can identify any need to immediately apply a corrective or preventative action. Consider existing compliance requirements—AI systems and models will likely use personal data, which means that applicable privacy regulations, e.g., GDPR, can apply alongside the EU AI Act. Revise existing policies—AI systems can perform a variety of tasks, but not all use cases may be compliant with applicable laws and regulations or fall within an enterprise’s risk appetite.\n",
      "\n",
      "Title: A Primer on the EU AI Act - OpenAI\n",
      "URL: https://openai.com/global-affairs/a-primer-on-the-eu-ai-act/\n",
      "Content: The AI Act is built upon a risk-based framework, with specific requirements for high-risk and unacceptable-risk AI systems. The Act requires companies to classify the risk level of their AI systems to determine the corresponding regulatory obligations, and sets out various categories or tiers of AI systems that each carry different obligations.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.answer)\n",
    "print('-'*100)\n",
    "print(results.news_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt_legal(suffix: str) -> str:\n",
    "    return (\n",
    "        \"\"\"You are an experienced attorney with decades of expertise, \n",
    "        known for your thorough understanding of legal frameworks and \n",
    "        your ability to articulate precise, formal, and well-reasoned arguments, collaborating with other experts.\n",
    "        Use the provided tools to progress towards answering the question.\n",
    "        If you are unable to fully answer, that's OK, another expert with different tools \n",
    "        will help where you left off. Execute what you can to make progress.\n",
    "        If you or any of the other experts have the final answer or deliverable,\n",
    "        prefix your response with FINAL ANSWER so the team knows to stop.\n",
    "        f\"\\n{suffix}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt_social(suffix: str) -> str:\n",
    "    return (\n",
    "        \"\"\"You are an expert social media strategist with extensive experience in creating highly engaging and platform-specific content across Instagram, TikTok, YouTube, LinkedIn, and other major platforms.\n",
    "        Your expertise includes crafting strategies that drive audience growth, boost engagement, and optimize monetization opportunities.\n",
    "        Provide practical, actionable advice tailored to the platform in focus.\n",
    "        Use the provided tools to progress towards answering the question.\n",
    "        If you are unable to fully answer, that's OK, another expert with different tools \n",
    "        will help where you left off. Execute what you can to make progress.\n",
    "        If you or any of the other experts have the final answer or deliverable,\n",
    "        prefix your response with FINAL ANSWER so the team knows to stop.\n",
    "        f\"\\n{suffix}\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return END\n",
    "    return goto\n",
    "\n",
    "\n",
    "# Research agent and node\n",
    "research_agent = create_react_agent(\n",
    "    model_openai,\n",
    "    tools=[tavily_tool],\n",
    "    state_modifier=make_system_prompt_legal(\n",
    "        \"You can only do legal research. You are working with an social media expert colleague.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def research_node(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"social_media_expert\", END]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"social_media_expert\")\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of research agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n",
    "\n",
    "\n",
    "social_media_agent = create_react_agent(\n",
    "    model_openai,\n",
    "    tools=[],\n",
    "    state_modifier=make_system_prompt_social(\n",
    "        \"You can only generate social media content. You are working with a researcher colleague.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def social_media_node(state: MessagesState) -> Command[Literal[\"researcher\", END]]:\n",
    "    result = social_media_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"social_media_expert\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"social_media_expert\", social_media_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'researcher': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987')]}}\n",
      "----\n",
      "{'social_media_expert': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872')]}}\n",
      "----\n",
      "{'researcher': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe')]}}\n",
      "----\n",
      "{'social_media_expert': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441')]}}\n",
      "----\n",
      "{'researcher': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441'), HumanMessage(content='approach to categorizing AI systems based on their risk. Each category imposes varying levels of compliance obligations:\\n\\n   - **Minimal Risk AI**: These systems face few requirements and can generally operate without regulatory oversight.\\n   - **Limited Risk AI**: These include systems with specific transparency obligations, such as chatbots needing to disclose their non-human nature.\\n   - **High-Risk AI**: This category necessitates rigorous checks, audits, and documentation, ensuring significant scrutiny on systems that affect', additional_kwargs={}, response_metadata={}, name='researcher', id='5ebc4c48-2b4f-42c8-993d-cc03c35b92ce')]}}\n",
      "----\n",
      "{'social_media_expert': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441'), HumanMessage(content='approach to categorizing AI systems based on their risk. Each category imposes varying levels of compliance obligations:\\n\\n   - **Minimal Risk AI**: These systems face few requirements and can generally operate without regulatory oversight.\\n   - **Limited Risk AI**: These include systems with specific transparency obligations, such as chatbots needing to disclose their non-human nature.\\n   - **High-Risk AI**: This category necessitates rigorous checks, audits, and documentation, ensuring significant scrutiny on systems that affect', additional_kwargs={}, response_metadata={}, name='researcher', id='5ebc4c48-2b4f-42c8-993d-cc03c35b92ce'), HumanMessage(content='human rights or public safety. Compliance with risk management systems and human oversight is emphasized.\\n\\n8. **Post-Market Monitoring**:\\n   - Once an AI system is deployed, continuous monitoring is required for high-risk categories to ensure compliance with regulations throughout its lifecycle. This includes gathering user feedback and addressing any identified issues.\\n\\n### Scope and Implications\\n\\nThe EU AI Act has far-reaching implications for various stakeholders including AI developers, companies deploying AI, public authorities, and end-users. It aims to:\\n\\n-', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='71764c09-a221-41ca-9f5d-33d24a400a37')]}}\n",
      "----\n",
      "{'researcher': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441'), HumanMessage(content='approach to categorizing AI systems based on their risk. Each category imposes varying levels of compliance obligations:\\n\\n   - **Minimal Risk AI**: These systems face few requirements and can generally operate without regulatory oversight.\\n   - **Limited Risk AI**: These include systems with specific transparency obligations, such as chatbots needing to disclose their non-human nature.\\n   - **High-Risk AI**: This category necessitates rigorous checks, audits, and documentation, ensuring significant scrutiny on systems that affect', additional_kwargs={}, response_metadata={}, name='researcher', id='5ebc4c48-2b4f-42c8-993d-cc03c35b92ce'), HumanMessage(content='human rights or public safety. Compliance with risk management systems and human oversight is emphasized.\\n\\n8. **Post-Market Monitoring**:\\n   - Once an AI system is deployed, continuous monitoring is required for high-risk categories to ensure compliance with regulations throughout its lifecycle. This includes gathering user feedback and addressing any identified issues.\\n\\n### Scope and Implications\\n\\nThe EU AI Act has far-reaching implications for various stakeholders including AI developers, companies deploying AI, public authorities, and end-users. It aims to:\\n\\n-', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='71764c09-a221-41ca-9f5d-33d24a400a37'), HumanMessage(content='enhance accountability and transparency in AI deployment, fostering trust among consumers and the broader public.\\n- ensure that AI technologies are used responsibly and ethically, reducing the likelihood of harmful outcomes or discriminatory practices. \\n- stimulate innovation by providing a clear framework for AI development, thus attracting both domestic and foreign investments in the EU AI sector.\\n- create a level playing field by establishing uniform standards across member states, reducing the legal complexities faced by businesses operating in multiple jurisdictions.\\n\\nThe Act also seeks to promote collaboration between', additional_kwargs={}, response_metadata={}, name='researcher', id='2fdccf14-3f9d-48ab-805a-9401bb8fa0fe')]}}\n",
      "----\n",
      "{'social_media_expert': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441'), HumanMessage(content='approach to categorizing AI systems based on their risk. Each category imposes varying levels of compliance obligations:\\n\\n   - **Minimal Risk AI**: These systems face few requirements and can generally operate without regulatory oversight.\\n   - **Limited Risk AI**: These include systems with specific transparency obligations, such as chatbots needing to disclose their non-human nature.\\n   - **High-Risk AI**: This category necessitates rigorous checks, audits, and documentation, ensuring significant scrutiny on systems that affect', additional_kwargs={}, response_metadata={}, name='researcher', id='5ebc4c48-2b4f-42c8-993d-cc03c35b92ce'), HumanMessage(content='human rights or public safety. Compliance with risk management systems and human oversight is emphasized.\\n\\n8. **Post-Market Monitoring**:\\n   - Once an AI system is deployed, continuous monitoring is required for high-risk categories to ensure compliance with regulations throughout its lifecycle. This includes gathering user feedback and addressing any identified issues.\\n\\n### Scope and Implications\\n\\nThe EU AI Act has far-reaching implications for various stakeholders including AI developers, companies deploying AI, public authorities, and end-users. It aims to:\\n\\n-', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='71764c09-a221-41ca-9f5d-33d24a400a37'), HumanMessage(content='enhance accountability and transparency in AI deployment, fostering trust among consumers and the broader public.\\n- ensure that AI technologies are used responsibly and ethically, reducing the likelihood of harmful outcomes or discriminatory practices. \\n- stimulate innovation by providing a clear framework for AI development, thus attracting both domestic and foreign investments in the EU AI sector.\\n- create a level playing field by establishing uniform standards across member states, reducing the legal complexities faced by businesses operating in multiple jurisdictions.\\n\\nThe Act also seeks to promote collaboration between', additional_kwargs={}, response_metadata={}, name='researcher', id='2fdccf14-3f9d-48ab-805a-9401bb8fa0fe'), HumanMessage(content='regulatory authorities and industry stakeholders, laying the groundwork for best practices in AI usage and ensuring ongoing dialogues about ethical standards and technological advancements. Furthermore, it emphasizes the importance of international cooperation in addressing global AI challenges and standards.\\n\\n### Summary of the EU AI Act\\n\\n1. **Risk-Based Classification**: AI systems are categorized into minimal, limited, high risk, and prohibited areas, each with tailored regulatory obligations.\\n2. **High-Risk Regulations**: High-risk systems require extensive oversight, risk management', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='ef88cb93-c420-419e-81eb-25363eb6f307')]}}\n",
      "----\n",
      "{'researcher': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441'), HumanMessage(content='approach to categorizing AI systems based on their risk. Each category imposes varying levels of compliance obligations:\\n\\n   - **Minimal Risk AI**: These systems face few requirements and can generally operate without regulatory oversight.\\n   - **Limited Risk AI**: These include systems with specific transparency obligations, such as chatbots needing to disclose their non-human nature.\\n   - **High-Risk AI**: This category necessitates rigorous checks, audits, and documentation, ensuring significant scrutiny on systems that affect', additional_kwargs={}, response_metadata={}, name='researcher', id='5ebc4c48-2b4f-42c8-993d-cc03c35b92ce'), HumanMessage(content='human rights or public safety. Compliance with risk management systems and human oversight is emphasized.\\n\\n8. **Post-Market Monitoring**:\\n   - Once an AI system is deployed, continuous monitoring is required for high-risk categories to ensure compliance with regulations throughout its lifecycle. This includes gathering user feedback and addressing any identified issues.\\n\\n### Scope and Implications\\n\\nThe EU AI Act has far-reaching implications for various stakeholders including AI developers, companies deploying AI, public authorities, and end-users. It aims to:\\n\\n-', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='71764c09-a221-41ca-9f5d-33d24a400a37'), HumanMessage(content='enhance accountability and transparency in AI deployment, fostering trust among consumers and the broader public.\\n- ensure that AI technologies are used responsibly and ethically, reducing the likelihood of harmful outcomes or discriminatory practices. \\n- stimulate innovation by providing a clear framework for AI development, thus attracting both domestic and foreign investments in the EU AI sector.\\n- create a level playing field by establishing uniform standards across member states, reducing the legal complexities faced by businesses operating in multiple jurisdictions.\\n\\nThe Act also seeks to promote collaboration between', additional_kwargs={}, response_metadata={}, name='researcher', id='2fdccf14-3f9d-48ab-805a-9401bb8fa0fe'), HumanMessage(content='regulatory authorities and industry stakeholders, laying the groundwork for best practices in AI usage and ensuring ongoing dialogues about ethical standards and technological advancements. Furthermore, it emphasizes the importance of international cooperation in addressing global AI challenges and standards.\\n\\n### Summary of the EU AI Act\\n\\n1. **Risk-Based Classification**: AI systems are categorized into minimal, limited, high risk, and prohibited areas, each with tailored regulatory obligations.\\n2. **High-Risk Regulations**: High-risk systems require extensive oversight, risk management', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='ef88cb93-c420-419e-81eb-25363eb6f307'), HumanMessage(content=', and compliance measures to protect health, safety, and fundamental rights.\\n3. **Prohibited AI Practices**: Includes banning manipulative AI uses, such as social scoring by authorities and exploiting vulnerable groups.\\n4. **Transparency and Accountability**: Mandates clear disclosures regarding AI system functionalities and ethical considerations.\\n5. **Data Governance**: Enforces standards on data quality, emphasizing the need for representative and bias-free datasets.\\n6. **Regulatory Sandboxes**: Facilitates innovation by allowing', additional_kwargs={}, response_metadata={}, name='researcher', id='fdb5aeb6-5cec-4dc9-9a70-b0bfa85d2c8d')]}}\n",
      "----\n",
      "{'social_media_expert': {'messages': [HumanMessage(content=\"Please explain the European Union's Artificial Intelligence Act (EU AI Act) in detail, covering its key provisions, scope, and implications. Then, provide a concise summary highlighting the most important points. After delivering the summary, conclude the response.\", additional_kwargs={}, response_metadata={}, id='4459c4e3-2d8e-482f-bc25-e8fcca273690'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 254, 'total_tokens': 286, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ce86910-e50c-4ea7-a32b-da42db9b1d47-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications'}, 'id': 'call_clQ9sgCWHRutV8ArDQw7YbAw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 32, 'total_tokens': 286, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/\", \"content\": \"In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\"}]', name='tavily_search_results_json', id='05e0b1a1-09c2-4493-bf74-05d5abd4338e', tool_call_id='call_clQ9sgCWHRutV8ArDQw7YbAw', artifact={'query': 'European Union Artificial Intelligence Act EU AI Act 2023 details provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act (EU AI Act) officially enters into force on 1 August 2024. The Act aims to foster responsible artificial intelligence development and deployment in the EU, addressing potential risks to citizens' health, safety, and fundamental rights. The AI Act includes provisions for establishing an AI governance system at both the EU and member-state levels, issuing secondary legislation to facilitate implementation and compliance, enforcing rules for AI developers and deployers, particularly concerning high-impact general-purpose AI (GPAI) models, and conducting ex-post evaluations to assess the law's relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.74318707, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'The Finalized EU Artificial Intelligence Act: Implications and Insights', 'url': 'https://cset.georgetown.edu/article/the-finalized-eu-artificial-intelligence-act-implications-and-insights/', 'content': 'In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases.', 'score': 0.72207695, 'raw_content': \"Center for Security and Emerging Technology\\n\\n      CSET    \\nThe Finalized EU Artificial Intelligence Act: Implications and Insights\\nMia Hoffmann\\nThe European Union's Artificial Intelligence Act has officially come into force today after more than five years of legislative processes and negotiations. While marking a significant milestone, it also initiates a prolonged phase of implementation, refinement, and enforcement. This blog post outlines key aspects of the regulation, such as rules for general-purpose AI and governance structures, and provides insights into its timeline and future expectations.\\nToday, the European Union’s landmark AI regulation, the Artificial Intelligence Act, comes into force. This concludes more than five years of lawmaking and negotiations, and inaugurates a much longer phase of implementation, refinement, and enforcement. Even though the law has been written, it is far from final. The last deliberations took place under significant time constraints due to the European Parliament elections in June of this year. As a result, many provisions of the regulation remain vague and require additional specifications to guide AI developers and deployers in their compliance efforts. Especially for the European Commission, the EU’s executive branch, which has been tasked with issuing a swath of secondary legislation, the real work begins now.\\nScope: The regulation applies to AI developers and deployers whose system or model, including its output, is on the EU market or otherwise in service in the EU, irrespective of their physical location inside or outside the EU. There are three broad exceptions:\\xa0\\nNotably, the regulation does not apply to EU developers exporting their technology for use outside of the 27 member countries. In other words, it is not prohibited to produce and export AI systems whose use is banned in the EU itself.\\xa0\\nDefinition of AI: The AI Act defines an AI system as “a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments,” (Art. 3(1)). As such, the EU’s definition is well-aligned with the Organisation for Economic Co-operation and Development and the definition used in the White House’s October 2023 AI executive order, a small yet noteworthy step of convergence.\\xa0\\xa0\\nAt the heart of the AI Act stands its risk-based approach, which classifies AI systems according to the level of risk they pose to health, safety, and fundamental rights. To do so, the AI Act categorizes AI systems into two broad groups: Single-purpose AI and general-purpose AI (GPAI). The risk level of single-purpose AI is determined by its use case, whereas that of GPAI is determined by its capabilities.\\nThe regulation distinguishes between four levels of risk for single-purpose AI systems: 1) unacceptable risk, 2) high risk, 3) transparency risk, and 4) minimal risk. The majority of AI systems will fall into the minimal-risk category (e.g., AI used to filter junk emails) and are not subject to any requirements. Developers are instead encouraged to follow voluntary codes of conduct.\\nSystems that are considered to pose transparency risks include AI that can generate synthetic content, as well as biometric categorization and emotion recognition systems. These come with transparency and notification obligations: AI-generated content must be identifiable as such, for example through watermarking or other state-of-the-art methods, and individuals who are interacting with a generative AI or who are subject to a biometric system’s operation must be notified.\\nAI systems that pose unacceptable risks to health, safety, and fundamental rights, as defined by the AI Act, are banned from EU markets. The types of AI systems that fall under this designation have grown over the course of negotiations to the following eight:\\xa0\\nThe majority of the regulatory requirements relate to high-risk AI systems. These can be one of two types:\\nFor an AI system in these sensitive contexts to be considered high-risk, it needs to materially influence the outcome of a decision or action. This means, for example, that an AI system that performs a narrow procedural task within the admissions process of a university—such as extracting names, addresses, and contact information from an application pool to populate a database of candidates—would be classified as low-risk despite the sensitivity of its use context.\\xa0\\xa0\\nHigh-risk AI systems are subject to a variety of requirements, which are laid out in the AI Act’s Chapter III, sections 2 and 3. They must meet accuracy, robustness and cybersecurity standards alongside provisions on data quality and governance for their training, testing, and validation data. In addition, they require strict monitoring and oversight. With the exception of uses in law enforcement and border management, actions or decisions taken on the basis of the output of a high-risk AI system must be reviewed and confirmed by two competent human supervisors. To facilitate this, high-risk AI systems must be equipped with understandable user interfaces, as well as logging and recording capabilities.\\xa0\\nIn addition to ensuring their system’s conformity with the above-described requirements, developers and deployers of high-risk AI systems face additional obligations. The cornerstone is the establishment of a quality management system by the developer that ensures its system’s conformity with the AI Act not only at launch but over the entire AI life cycle. Under the quality management system, developers must set up and implement a risk management framework, as well as an accountability framework, and draft detailed technical documentation that describes, among other things, the development methodologies, model specifications, datasets used, testing and validation strategies, and the result of performance evaluations. They must also implement a post-market monitoring system, including procedures for incident logging, identification, and reporting. Once all this is complete, developers must undertake a conformity assessment that verifies the fulfillment of all requirements, and register their high-risk AI system in an EU-wide database.\\xa0\\nDeployers, on the other hand, are responsible for ensuring the AI system is operated in line with its intended purpose and instructions, for implementing monitoring and competent human oversight, and for complying with notification obligations towards third parties. Deployers in the areas of healthcare, education, housing, social services, administration, banking, and insurance must furthermore perform a fundamental rights impact assessment prior to deploying the high-risk AI system.\\xa0\\nA general-purpose AI model is defined as “an AI model […] that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications […].” (Art. 3(63)). The AI Act distinguishes between GPAI models and systems with and without systemic risks. Under this classification, all GPAI models and systems are subject to some requirements, while only some must comply with additional obligations.\\xa0\\nAll developers of GPAI models are required to prepare and maintain detailed technical documentation of the model and provide this documentation to authorities upon request. They are furthermore obligated to facilitate compliance with the law for downstream developers who wish to integrate their model into their AI system by providing them with additional necessary documentation, for example, on model interactions with other hardware or software.\\xa0GPAI developers are expected to comply with EU copyright law and prepare and publish a summary of the content used in the training of their model.\\xa0\\nSome GPAI are classified as posing systemic risks. In the AI Act, systemic risks are a direct result of a GPAI model’s high-impact capabilities, which may pose an inherent threat to public health, safety, security, fundamental rights, or society as a whole, or are risky due to the model’s widespread integration in the EU market. Until more appropriate benchmarks and model evaluation methodologies are developed, a GPAI model is considered to pose systemic risks when a) its training requires >10^25 FLOPS in computing power or b) it is designated as such by the European Commission based on metrics such as the number of registered users or model parameters.\\xa0\\nDevelopers of GPAI models with systemic risks must, in addition to the obligations for all GPAI developers, establish a risk management system, perform additional model evaluations, engage in incident monitoring and reporting, and ensure appropriate levels of model cybersecurity.\\nAI models, systems, and components released under a free and open-source license are exempt from many, though not all, requirements of the regulation.\\nFailure to comply with the AI Act’s requirements is expensive. Penalties range from EUR 7.5M (or 1% of global annual turnover, whichever is higher) for supplying incorrect or misleading information to the authorities or during the conformity assessment process, to up to EUR 35M (or 7% of global annual turnover) for placing a banned AI system on the EU market.\\nEuropean Commission/AI Office: At the core of the AI Act’s overall implementation and governance efforts is the European Commission’s newly founded AI Office. Opened just over a month ago on June 16, 2024, the AI Office and its 140 staff are tasked with more than 100 specific responsibilities under the Act that must be carried out over the following months and years. Broadly, these fall into four categories: 1) Establishing the AI governance system at EU and member-state level; 2) Issuing secondary legislation that facilitates implementation of and compliance with the regulation; 3) Enforcing the rules for AI developers and deployers, with particular regards to GPAI; and 4) Conducting ex-post evaluations of the law to assess its relevance and appropriateness of thresholds and lists of high-risk and prohibited use cases. A full list of the responsibilities and corresponding timelines can be found here.\\nEuropean AI Board: The board consists of representatives from EU member states tasked with preventing regulatory fragmentation and supporting its harmonized implementation across member countries and the AI Office.\\nAdvisory Forum: The advisory forum consists of stakeholders from industry, small and medium-sized enterprises, academia, and civil society. It provides technical expertise from a diverse set of perspectives to the AI Office and the Board to be taken into consideration in the implementation process.\\nScientific Panel of Independent Experts: Members of the panel are experts appointed by the European Commission who support the AI Office’s enforcement efforts as regards to GPAI. They are specifically tasked with identifying systemic risks and providing guidance on model classification based on the latest scientific understanding.\\nMarket surveillance authorities: Each EU member country must designate a national market surveillance authority within the next year. They are in charge of monitoring and enforcing compliance in their national markets, but tasks also include managing incident tracking, supervising regulatory sandboxes, and handling citizen complaints. Data protection authorities have made the case for taking over these duties, pointing to their long experience providing independent oversight and developing guidelines, as well as their expertise in the interdisciplinary field of data processing and fundamental rights. By design of the AI Act, they will be in charge of overseeing AI use in the sectors of law enforcement, border control and migration, as well as judicial and electoral administration.\\xa0\\nNotified bodies: Any organization with sufficient expertise may apply to become a notified body, in other words, an accredited algorithmic auditor. They are independent and accredited organizations (or other legal entities) authorized to conduct conformity assessments for high-risk AI systems. The AI Act’s reliance on notified bodies to assess developers’ and deployers’ compliance efforts appears like an attempt to stimulate the AI audit industry in the EU. Yet, since only a few types of high-risk systems require a conformity assessment by a third party, this effect may be overall dampened.\\xa0\\nThe AI Act enters into force on August 1, 2024, but the law as a whole only becomes applicable on August 2, 2026, two years later. This gives AI developers and deployers additional time to familiarize themselves with the requirements, set up the necessary compliance procedures and bring their AI systems into conformity. However, the regulation provides for three special transition periods for certain categories of rules:\\nMoreover, for AI models that are already on the EU market, the AI Act provides for extended compliance periods, ranging from 2027 for GPAI to 2030 for high-risk AI. As such, a visible regulatory impact before 2026 is unlikely. The next year will require substantial investment in setting up the institutional governance structure, both at the EU and national levels. With limited budgets (the AI Office is endowed with only EUR 46.5M, national bodies will likely have far less), attracting the necessary talent to Brussels and all corners of the EU will present a tremendous challenge to the AI Act’s implementation and enforcement.\\xa0\\nCritically, despite the AI Act’s adoption, regulatory uncertainty on how to comply with its requirements remains high. The regulation relies heavily on technical standards to demonstrate conformity, but compared to other sectors, the current AI standards landscape is still in its infancy. Standards development is a complex and lengthy process, and the European Committee for Standardization (CEN), as well as the European Committee for Electrotechnical Standardization (CENELEC)—the European standard-making bodies—are not expected to issue harmonized standards that operationalize the requirements of the AI Act before 2027. To bridge the period after the application of the first requirements, one year into the AI Act’s entry into force, the AI Office is charged with issuing Codes of Practice to guide GPAI developers in their compliance efforts. While it is yet unclear what these Codes of Practice will look like, their development will likely involve multi-stakeholder consultations, working groups for different obligations of GPAI developers, and the definition of measures and key performance indicators whose operationalization will lead to a presumption of conformity with the requirements of the AI Act.\\n\\n              Assessment\\n          \\n\\n              Peer Watch\\n          \\nRelated Content\\nThe EU AI Act is nearing formal adoption and implementation. Read this blog post, with updated analysis following the December 2023 political agreement, by CSET’s resident EU expert and Research Fellow, Mia Hoffmann. Learn what… Read More\\n\\n        The Center for Security and Emerging Technology within Georgetown University's Walsh School of Foreign Service provides decision-makers with data-driven analysis on the security implications of emerging technologies.\\r\\n\\n\\t  \\ncset@georgetown.edu\\ndanny.hague@georgetown.edu\\n\\n\"}], 'response_time': 2.94}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'function': {'arguments': '{\"query\":\"European Union Artificial Intelligence Act 2023 summary provisions implications\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 592, 'total_tokens': 621, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43ef993d-3876-48ab-ae80-db04ce020735-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications'}, 'id': 'call_Xu8dYe3GXMFKKEgWHttmrn6o', 'type': 'tool_call'}], usage_metadata={'input_tokens': 592, 'output_tokens': 29, 'total_tokens': 621, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en\", \"content\": \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens\\' health, safety, and fundamental rights.\"}, {\"url\": \"https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law\", \"content\": \"Background\\\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\\\nMeasures to support innovation and SMEs\\\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\\\n Further information\\\\nProduct information\\\\nShare this page:\\\\nNews\\\\nParliament in your country\\\\nTools\\\\nThe President of the European Parliament\\\\nEuropean Parliament\\\\nThe Parliament on social media\\\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\\\n Next steps\\\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).\"}]', name='tavily_search_results_json', id='a8d6b9af-e574-4052-a1dd-908f6f37fc62', tool_call_id='call_Xu8dYe3GXMFKKEgWHttmrn6o', artifact={'query': 'European Union Artificial Intelligence Act 2023 summary provisions implications', 'follow_up_questions': None, 'answer': \"The European Union Artificial Intelligence Act 2023, set to enter into force on 1 August 2024, aims to foster responsible AI development and deployment within the EU. It addresses potential risks to citizens' health, safety, and fundamental rights. The Act responds to citizens' proposals from the Conference on the Future of Europe, focusing on enhancing competitiveness, ensuring a safe and trustworthy society, promoting digital innovation, and improving citizens' access to information. It mandates clear labeling of artificial or manipulated content like deepfakes. To support innovation, regulatory sandboxes and real-world testing will be established at the national level for SMEs and start-ups. The Act will be fully applicable 24 months after its entry into force, with specific timelines for different provisions: bans on prohibited practices apply six months after entry into force, codes of practice in nine months, general-purpose AI rules in 12 months, and obligations for high-risk systems in 36 months. The regulation is still subject to a final lawyer-linguist check and is expected to be adopted before the end of the current legislature.\", 'images': [], 'results': [{'title': 'AI Act enters into force - European Commission', 'url': 'https://commission.europa.eu/news/ai-act-enters-force-2024-08-01_en', 'content': \"On 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force.The Act aims to foster responsible artificial intelligence development and deployment in the EU.. Proposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the AI Act addresses potential risks to citizens' health, safety, and fundamental rights.\", 'score': 0.67706895, 'raw_content': \"AI Act enters into force\\nOn 1 August 2024, the European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelligence development and deployment in the EU.\\nProposed by the Commission in April 2021 and agreed by the European Parliament and the Council in December 2023, the\\xa0AI Act\\xa0addresses potential risks to citizens’ health, safety, and fundamental rights. It provides developers and deployers with clear requirements and obligations regarding specific uses of AI while reducing administrative and financial burdens for businesses.\\nThe AI Act introduces a uniform framework across all EU countries, based on a forward-looking definition of AI and a risk-based approach:\\nThe EU aspires to be the global leader in safe AI. By developing a strong regulatory framework based on human rights and fundamental values, the EU can develop an AI ecosystem that benefits everyone. This means better healthcare, safer and cleaner transport, and improved public services for citizens. It brings innovative products and services, particularly in energy, security, and healthcare, as well as higher productivity and more efficient manufacturing for businesses, while governments can benefit from cheaper and more sustainable services such as transport, energy and waste management.\\nRecently, the Commission has launched a consultation on a Code of Practice for providers of general-purpose Artificial Intelligence (GPAI) models. This Code, foreseen by the AI Act, will address critical areas such as transparency, copyright-related rules, and risk management.\\xa0GPAI providers with operations in the EU, businesses, civil society representatives, rights holders and academic experts are invited to submit their views and findings, which will feed into the Commission's upcoming draft of the Code of Practice on GPAI models.\\nThe provisions on GPAI will enter into application in 12 months. The Commission expects to finalise the Code of Practice by April 2025. In addition, the feedback from the consultation will also inform the work of the\\xa0AI Office, which will supervise the implementation and enforcement of the AI Act rules on GPAI.\\nFor more information\\nEuropean Artificial Intelligence Act comes into force - press release\\nArtificial Intelligence - Q&A\\nMore about the European AI Act\\nExcellence and trust in artificial intelligence\\nAI Act: Have Your Say on Trustworthy General-Purpose AI\\nEuropean AI Office\\nDetails\\nShare this page\"}, {'title': 'Artificial Intelligence Act: MEPs adopt landmark law | News | European ...', 'url': 'https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law', 'content': 'Background\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\n Additionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\n Further information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links It will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\n Next steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure).', 'score': 0.52948296, 'raw_content': 'Artificial Intelligence Act: MEPs adopt landmark law\\nShare this page:\\nOn Wednesday, Parliament approved the Artificial Intelligence Act that ensures safety and compliance with fundamental rights, while boosting innovation.\\nThe regulation, agreed in negotiations with member states in December 2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.\\nIt aims to protect fundamental rights, democracy, the rule of law and environmental sustainability from high-risk AI, while boosting innovation and establishing Europe as a leader in the field. The regulation establishes obligations for AI based on its potential risks and level of impact.\\nBanned applications\\nThe new rules ban certain AI applications that threaten citizens’ rights, including biometric categorisation systems based on sensitive characteristics and untargeted scraping of facial images from the internet or CCTV footage to create facial recognition databases. Emotion recognition in the workplace and schools, social scoring, predictive policing (when it is based solely on profiling a person or assessing their characteristics), and AI that manipulates human behaviour or exploits people’s vulnerabilities will also be forbidden.\\nLaw enforcement exemptions\\nThe use of biometric identification systems (RBI) by law enforcement is prohibited in principle, except in exhaustively listed and narrowly defined situations. “Real-time” RBI can only be deployed if strict safeguards are met, e.g. its use is limited in time and geographic scope and subject to specific prior judicial or administrative authorisation. Such uses may include, for example, a targeted search of a missing person or preventing a terrorist attack. Using such systems post-facto (“post-remote RBI”) is considered a high-risk use case, requiring judicial authorisation being linked to a criminal offence.\\nObligations for high-risk systems\\nClear obligations are also foreseen for other high-risk AI systems (due to their significant potential harm to health, safety, fundamental rights, environment, democracy and the rule of law). Examples of high-risk AI uses include critical infrastructure, education and vocational training, employment, essential private and public services (e.g. healthcare, banking), certain systems in law enforcement, migration and border management, justice and democratic processes (e.g. influencing elections). Such systems must assess and reduce risks, maintain use logs, be transparent and accurate, and ensure human oversight. Citizens will have a right to submit complaints about AI systems and receive explanations about decisions based on high-risk AI systems that affect their rights.\\nTransparency requirements\\nGeneral-purpose AI (GPAI) systems, and the GPAI models they are based on, must meet certain transparency requirements, including compliance with EU copyright law and publishing detailed summaries of the content used for training. The more powerful GPAI models that could pose systemic risks will face additional requirements, including performing model evaluations, assessing and mitigating systemic risks, and reporting on incidents.\\nAdditionally, artificial or manipulated images, audio or video content (“deepfakes”) need to be clearly labelled as such.\\nMeasures to support innovation and SMEs\\nRegulatory sandboxes and real-world testing will have to be established at the national level, and made accessible to SMEs and start-ups, to develop and train innovative AI before its placement on the market.\\nQuotes\\nDuring the plenary debate on Tuesday, the Internal Market Committee co-rapporteur Brando Benifei (S&D, Italy) said: “We finally have the world’s first binding law on artificial intelligence, to reduce risks, create opportunities, combat discrimination, and bring transparency. Thanks to Parliament, unacceptable AI practices will be banned in Europe and the rights of workers and citizens will be protected. The AI Office will now be set up to support companies to start complying with the rules before they enter into force. We ensured that human beings and European values are at the very centre of AI’s development”.\\nCivil Liberties Committee co-rapporteur Dragos Tudorache (Renew, Romania) said: “The EU has delivered. We have linked the concept of artificial intelligence to the fundamental values that form the basis of our societies. However, much work lies ahead that goes beyond the AI Act itself. AI will push us to rethink the social contract at the heart of our democracies, our education models, labour markets, and the way we conduct warfare. The AI Act is a starting point for a new model of governance built around technology. We must now focus on putting this law into practice”.\\nNext steps\\nThe regulation is still subject to a final lawyer-linguist check and is expected to be finally adopted before the end of the legislature (through the so-called corrigendum procedure). The law also needs to be formally endorsed by the Council.\\nIt will enter into force twenty days after its publication in the official Journal, and be fully applicable 24 months after its entry into force, except for: bans on prohibited practises, which will apply six months after the entry into force date; codes of practise (nine months after entry into force); general-purpose AI rules including governance (12 months after entry into force); and obligations for high-risk systems (36 months).\\nBackground\\nThe Artificial Intelligence Act responds directly to citizens’ proposals from the Conference on the Future of Europe (COFE), most concretely to proposal 12(10) on enhancing EU’s competitiveness in strategic sectors, proposal 33(5) on a safe and trustworthy society, including countering disinformation and ensuring humans are ultimately in control, proposal 35 on promoting digital innovation, (3) while ensuring human oversight and (8) trustworthy and responsible use of AI, setting safeguards and ensuring transparency, and proposal 37 (3) on using AI and digital tools to improve citizens’ access to information, including persons with disabilities.\\nContacts:\\nYasmina YAKIMOVA\\nJanne OJAMO\\nFurther information\\nProduct information\\nShare this page:\\nNews\\nParliament in your country\\nTools\\nThe President of the European Parliament\\nEuropean Parliament\\nThe Parliament on social media\\nInformation links'}], 'response_time': 3.3}), HumanMessage(content=\"The European Union's Artificial Intelligence Act (EU AI Act) is a comprehensive regulatory framework aimed at fostering the responsible development and deployment of AI technologies within the EU. Proposed in April 2021 and finalized in December 2023, the Act is set to come into force on August 1, 2024.\\n\\n### Key Provisions\\n\\n1. **Risk-Based Classification**:\\n   - The Act categorizes AI systems into different risk tiers: minimal risk, limited risk, high risk, and\", additional_kwargs={}, response_metadata={}, name='researcher', id='905036ae-01f7-42dd-b0b1-f387cc98f987'), HumanMessage(content='prohibited risks. Each category has corresponding requirements and obligations for developers and deployers.\\n\\n2. **High-Risk AI Regulations**:\\n   - High-risk AI systems, particularly those that have significant implications for health, safety, and fundamental rights (e.g., biometric identification and critical infrastructure), require strict compliance measures including documentation, risk assessment, and human oversight.\\n\\n3. **Prohibited AI Practices**:\\n   - Certain AI applications are completely banned, such as systems that manipulate human behavior through social scoring', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='e52db0d0-f67c-425f-a3d9-bd7603523872'), HumanMessage(content='and those that employ subliminal techniques or exploit information of vulnerable groups. This includes the use of AI for social scoring by public authorities.\\n\\n4. **Transparency and Accountability**:\\n   - The Act mandates transparency obligations for AI systems, particularly those deemed high-risk. This includes clear disclosures about the system’s capabilities and limitations, as well as ethical considerations regarding the use of AI outcomes.\\n\\n5. **Data Governance**:\\n   - There are specific provisions concerning the quality and governance of data used in AI', additional_kwargs={}, response_metadata={}, name='researcher', id='fc800a80-9d7e-4867-b3dd-8604211572fe'), HumanMessage(content='systems. The Act emphasizes the need for high-quality training data, stipulating that data must be relevant, representative, and free from bias to prevent discriminatory outcomes.\\n\\n6. **Regulatory Sandboxes**:\\n   - The Act encourages the establishment of regulatory sandboxes at the national level. These are controlled environments where businesses, particularly SMEs and startups, can test their AI innovations in real-world conditions under regulatory supervision.\\n\\n7. **Categorization of AI Systems**:\\n   - The AI Act introduces a systematic', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='07172ac7-e633-4d93-8754-3390dbc17441'), HumanMessage(content='approach to categorizing AI systems based on their risk. Each category imposes varying levels of compliance obligations:\\n\\n   - **Minimal Risk AI**: These systems face few requirements and can generally operate without regulatory oversight.\\n   - **Limited Risk AI**: These include systems with specific transparency obligations, such as chatbots needing to disclose their non-human nature.\\n   - **High-Risk AI**: This category necessitates rigorous checks, audits, and documentation, ensuring significant scrutiny on systems that affect', additional_kwargs={}, response_metadata={}, name='researcher', id='5ebc4c48-2b4f-42c8-993d-cc03c35b92ce'), HumanMessage(content='human rights or public safety. Compliance with risk management systems and human oversight is emphasized.\\n\\n8. **Post-Market Monitoring**:\\n   - Once an AI system is deployed, continuous monitoring is required for high-risk categories to ensure compliance with regulations throughout its lifecycle. This includes gathering user feedback and addressing any identified issues.\\n\\n### Scope and Implications\\n\\nThe EU AI Act has far-reaching implications for various stakeholders including AI developers, companies deploying AI, public authorities, and end-users. It aims to:\\n\\n-', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='71764c09-a221-41ca-9f5d-33d24a400a37'), HumanMessage(content='enhance accountability and transparency in AI deployment, fostering trust among consumers and the broader public.\\n- ensure that AI technologies are used responsibly and ethically, reducing the likelihood of harmful outcomes or discriminatory practices. \\n- stimulate innovation by providing a clear framework for AI development, thus attracting both domestic and foreign investments in the EU AI sector.\\n- create a level playing field by establishing uniform standards across member states, reducing the legal complexities faced by businesses operating in multiple jurisdictions.\\n\\nThe Act also seeks to promote collaboration between', additional_kwargs={}, response_metadata={}, name='researcher', id='2fdccf14-3f9d-48ab-805a-9401bb8fa0fe'), HumanMessage(content='regulatory authorities and industry stakeholders, laying the groundwork for best practices in AI usage and ensuring ongoing dialogues about ethical standards and technological advancements. Furthermore, it emphasizes the importance of international cooperation in addressing global AI challenges and standards.\\n\\n### Summary of the EU AI Act\\n\\n1. **Risk-Based Classification**: AI systems are categorized into minimal, limited, high risk, and prohibited areas, each with tailored regulatory obligations.\\n2. **High-Risk Regulations**: High-risk systems require extensive oversight, risk management', additional_kwargs={}, response_metadata={}, name='social_media_expert', id='ef88cb93-c420-419e-81eb-25363eb6f307'), HumanMessage(content=', and compliance measures to protect health, safety, and fundamental rights.\\n3. **Prohibited AI Practices**: Includes banning manipulative AI uses, such as social scoring by authorities and exploiting vulnerable groups.\\n4. **Transparency and Accountability**: Mandates clear disclosures regarding AI system functionalities and ethical considerations.\\n5. **Data Governance**: Enforces standards on data quality, emphasizing the need for representative and bias-free datasets.\\n6. **Regulatory Sandboxes**: Facilitates innovation by allowing', additional_kwargs={}, response_metadata={}, name='researcher', id='fdb5aeb6-5cec-4dc9-9a70-b0bfa85d2c8d'), HumanMessage(content=\"startups and SMEs to test AI technologies in controlled environments under regulatory oversight.\\n7. **Post-Market Monitoring**: Requires continuous oversight of high-risk AI systems after deployment to ensure compliance and address feedback.\\n\\n### Concluding Thoughts\\n\\nThe European Union's Artificial Intelligence Act represents a significant step toward ensuring that AI technologies are developed and used in a safe, ethical, and responsible manner. By establishing clear classifications and requirements based on risk levels, the Act aims to protect citizens while promoting innovation within the AI sector\", additional_kwargs={}, response_metadata={}, name='social_media_expert', id='f4b897c0-7c97-48de-8567-60935e9dbf98')]}}\n",
      "----\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m      2\u001b[0m     {\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m},\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m----\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ana Belen\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai-wise-council-U8tERo2L-py3.12\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1690\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1682\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[0;32m   1683\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1684\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1688\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[0;32m   1689\u001b[0m     )\n\u001b[1;32m-> 1690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[0;32m   1692\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[1;31mGraphRecursionError\u001b[0m: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Please explain the European Union's Artificial Intelligence Act (EU AI Act) \"\n",
    "                \"in detail, covering its key provisions, scope, and implications. Then, provide \"\n",
    "                \"a concise summary highlighting the most important points. After delivering \"\n",
    "                \"the summary, conclude the response.\",\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 10},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Agent Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:93: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:93: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:93: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:93: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\Ana Belen\\AppData\\Local\\Temp\\ipykernel_9140\\1965927258.py:93: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  return f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
      "C:\\Users\\Ana Belen\\AppData\\Local\\Temp\\ipykernel_9140\\1965927258.py:93: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  return f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n"
     ]
    }
   ],
   "source": [
    "### Tooling\n",
    "\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "_TEMP_DIRECTORY = TemporaryDirectory()\n",
    "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
    "\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[list[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to read the document from.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ],\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\"\n",
    "\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> Callable:\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "        next: Literal[*options]\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Search agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "search_agent_2 = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "\n",
    "def search_2_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent_2.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search_2\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"search_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"search_2\", search_2_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'search'}}\n",
      "---\n",
      "{'search': {'messages': [HumanMessage(content='Taylor Swift\\'s next tour is the \"Eras Tour,\" which includes several upcoming dates in 2023 and 2024. Here are some key dates:\\n\\n### 2023\\n- **November 24, 2023** - São Paulo, BR @ Allianz Parque\\n- **November 25, 2023** - São Paulo, BR @ Allianz Parque\\n- **November 26, 2023** - São Paulo, BR @ Allianz Parque\\n\\n### 2024\\n- **February 7, 2024** - Tokyo, JP @ Aviva Stadium\\n- **May 30, 2024** - Madrid, ES @ Estadio Santiago Bernabéu\\n- **June 2, 2024** - Lyon, FR @ Groupama Stadium\\n- **June 14, 2024** - Liverpool, UK @ Estádio Nilton Santos\\n- **July 13, 2024** - Milan, IT @ San Siro Stadium\\n- **August 16, 2024** - London, UK @ Estádio da Luz\\n\\nFor the full list of dates and details, you can refer to [this article](https://uproxx.com/pop/taylor-swift-2023-2024-tour-dates-eras/).', additional_kwargs={}, response_metadata={}, name='search', id='6cec7844-7afe-437c-9ab5-9d7be33fa02b')]}}\n",
      "---\n",
      "{'supervisor': {'next': '__end__'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in research_graph.stream(\n",
    "    {\"messages\": [(\"user\", \"when is Taylor Swift's next tour?\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Document agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "doc_writer_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_document, edit_document, read_document],\n",
    "    state_modifier=(\n",
    "        \"You can read, write and edit documents based on note-taker's outlines. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[create_outline, read_document],\n",
    "    state_modifier=(\n",
    "        \"You can read documents and create outlines for the document writer. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "chart_generating_agent = create_react_agent(\n",
    "    llm, tools=[read_document, python_repl_tool]\n",
    ")\n",
    "\n",
    "\n",
    "def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = chart_generating_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "doc_writing_supervisor_node = make_supervisor_node(\n",
    "    llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph here\n",
    "paper_writing_builder = StateGraph(State)\n",
    "paper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)\n",
    "paper_writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "paper_writing_builder.add_node(\"note_taker\", note_taking_node)\n",
    "paper_writing_builder.add_node(\"chart_generator\", chart_generating_node)\n",
    "\n",
    "paper_writing_builder.add_edge(START, \"supervisor\")\n",
    "paper_writing_graph = paper_writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(paper_writing_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"research_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def call_paper_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the graph.\n",
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_paper_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(super_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'research_team'}}\n",
      "---\n",
      "{'research_team': {'messages': [HumanMessage(content=\"### Updated Report on AI Agents (2023)\\n\\n**Definition and Overview**\\nAI agents are sophisticated software programs designed to perform tasks autonomously, mimicking human intelligence. These agents operate based on goals set by human operators, allowing them to collect and analyze data from their environments to make informed decisions and act independently. The evolution in AI agents is influenced significantly by advancements in large language models (LLMs) and their integration into various applications.\\n\\n**Functionality**\\nThe core functionality of AI agents involves the ability to analyze vast amounts of information and make decisions based on learned patterns and experiences. Unlike traditional scripts that follow preset instructions, AI agents utilize adaptive learning algorithms that enable them to respond to new information and changing circumstances. Recent advancements, such as **Chain of Thought prompting** and historical memory integration (as seen in projects like Stanford’s Generative Simulacra), enhance their reasoning and planning capabilities. These enhancements allow AI agents to perform complex tasks, like analyzing legal documents or generating marketing insights.\\n\\n**Applications**\\nAI agents have found applications across multiple sectors, including but not limited to:\\n\\n- **Customer Service:** Chatbots that autonomously address user inquiries and provide support.\\n- **Business Intelligence:** Applications that analyze market data and recommend strategic actions.\\n- **Content Creation:** Tools that summarize news articles or generate newsletters, providing value in information dissemination.\\n- **Legal Analysis:** Systems that can review legal documents and offer jurisdictional insights.\\n\\nThe latest developments have led to the creation of focused applications, like bots capable of detailed data analyses specific to particular domains.\\n\\n**Conclusion**\\nAI agents signify a transformative stage in artificial intelligence, moving beyond basic task automation to becoming integral tools in decision-making and strategic planning. As AI and its related technologies continue to evolve, the functionality and scope of AI agents are expected to expand, potentially reshaping workflows and enhancing operational efficiency across various industries.\\n\\n**References**\\n1. [AWS: What is AI Agents?](https://aws.amazon.com/what-is/ai-agents/)\\n2. [Creaitor: AI Agents Explained](https://www.creaitor.ai/blog/ai-agents-explained)\\n3. [AI Infrastructure: Agents, LLMs, and Smart Apps - Report 2023](https://ai-infrastructure.org/agents-llms-and-smart-apps-report-2023/)\\n4. [Gartner: What's New in Artificial Intelligence from the 2023 Gartner Hype Cycle](https://www.gartner.com/en/articles/what-s-new-in-artificial-intelligence-from-the-2023-gartner-hype-cycle)\", additional_kwargs={}, response_metadata={}, name='research_team', id='570ed854-a1d1-4f0f-83ea-1fa37c7bae48')]}}\n",
      "---\n",
      "{'supervisor': {'next': 'writing_team'}}\n",
      "---\n",
      "{'writing_team': {'messages': [HumanMessage(content=\"### AI Agents Report (2023)\\n\\n**Definition and Overview**  \\nAI agents are sophisticated software programs designed to perform tasks autonomously, mimicking human intelligence. These agents operate based on goals set by human operators, allowing them to collect and analyze data from their environments to make informed decisions and act independently. The evolution in AI agents is influenced significantly by advancements in large language models (LLMs) and their integration into various applications.\\n\\n**Functionality**  \\nThe core functionality of AI agents involves the ability to analyze vast amounts of information and make decisions based on learned patterns and experiences. Unlike traditional scripts that follow preset instructions, AI agents utilize adaptive learning algorithms that enable them to respond to new information and changing circumstances. Recent advancements, such as **Chain of Thought prompting** and historical memory integration (as seen in projects like Stanford’s Generative Simulacra), enhance their reasoning and planning capabilities. These enhancements allow AI agents to perform complex tasks, like analyzing legal documents or generating marketing insights.\\n\\n**Applications**  \\nAI agents have found applications across multiple sectors, including but not limited to:  \\n- **Customer Service:** Chatbots that autonomously address user inquiries and provide support.  \\n- **Business Intelligence:** Applications that analyze market data and recommend strategic actions.  \\n- **Content Creation:** Tools that summarize news articles or generate newsletters, providing value in information dissemination.  \\n- **Legal Analysis:** Systems that can review legal documents and offer jurisdictional insights.  \\n\\nThe latest developments have led to the creation of focused applications, like bots capable of detailed data analyses specific to particular domains.\\n\\n**Conclusion**  \\nAI agents signify a transformative stage in artificial intelligence, moving beyond basic task automation to becoming integral tools in decision-making and strategic planning. As AI and its related technologies continue to evolve, the functionality and scope of AI agents are expected to expand, potentially reshaping workflows and enhancing operational efficiency across various industries.\\n\\n**References**  \\n1. [AWS: What is AI Agents?](https://aws.amazon.com/what-is/ai-agents/)  \\n2. [Creaitor: AI Agents Explained](https://www.creaitor.ai/blog/ai-agents-explained)  \\n3. [AI Infrastructure: Agents, LLMs, and Smart Apps - Report 2023](https://ai-infrastructure.org/agents-llms-and-smart-apps-report-2023/)  \\n4. [Gartner: What's New in Artificial Intelligence from the 2023 Gartner Hype Cycle](https://www.gartner.com/en/articles/what-s-new-in-artificial-intelligence-from-the-2023-gartner-hype-cycle)\\n\\n---\\n\\n### Outline for AI Agents Report\\n\\n1. Definition and Overview  \\n2. Functionality  \\n3. Applications  \\n4. Conclusion  \\n5. References  \", additional_kwargs={}, response_metadata={}, name='writing_team', id='14fae060-b7b2-47e3-a5be-7b27b8fe57d3')]}}\n",
      "---\n",
      "{'supervisor': {'next': '__end__'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Research AI agents and write a brief report about them.\")\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tool = tavily_tool.invoke({\"args\": {'query': query}, \"type\": \"tool_call\", \"id\": \"foo\", \"name\": \"tavily\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='[{\"url\": \"https://www.isaca.org/resources/white-papers/2024/understanding-the-eu-ai-act\", \"content\": \"The EU AI Act requires that providers of high-risk AI systems use a postmarket monitoring system to collect and review information relevant to the performance of the AI system so they can identify any need to immediately apply a corrective or preventative action. Consider existing compliance requirements—AI systems and models will likely use personal data, which means that applicable privacy regulations, e.g., GDPR, can apply alongside the EU AI Act. Revise existing policies—AI systems can perform a variety of tasks, but not all use cases may be compliant with applicable laws and regulations or fall within an enterprise’s risk appetite.\"}, {\"url\": \"https://openai.com/global-affairs/a-primer-on-the-eu-ai-act/\", \"content\": \"The AI Act is built upon a risk-based framework, with specific requirements for high-risk and unacceptable-risk AI systems. The Act requires companies to classify the risk level of their AI systems to determine the corresponding regulatory obligations, and sets out various categories or tiers of AI systems that each carry different obligations.\"}]', name='tavily_search_results_json', tool_call_id='foo', artifact={'query': 'What are the main requirements of the EU AI Act for high-risk AI systems?', 'follow_up_questions': None, 'answer': 'The EU AI Act for high-risk AI systems mandates the use of a postmarket monitoring system to collect and review performance information, allowing for immediate corrective or preventative actions. Providers must classify the risk level of their AI systems to determine regulatory obligations, ensuring compliance with applicable laws and regulations such as GDPR. Additionally, existing policies must be revised to ensure all use cases align with legal requirements and enterprise risk appetite.', 'images': [], 'results': [{'title': 'Understanding the EU AI Act: Requirements and Next Steps - ISACA', 'url': 'https://www.isaca.org/resources/white-papers/2024/understanding-the-eu-ai-act', 'content': 'The EU AI Act requires that providers of high-risk AI systems use a postmarket monitoring system to collect and review information relevant to the performance of the AI system so they can identify any need to immediately apply a corrective or preventative action. Consider existing compliance requirements—AI systems and models will likely use personal data, which means that applicable privacy regulations, e.g., GDPR, can apply alongside the EU AI Act. Revise existing policies—AI systems can perform a variety of tasks, but not all use cases may be compliant with applicable laws and regulations or fall within an enterprise’s risk appetite.', 'score': 0.9446333, 'raw_content': \"Understanding the EU AI Act: Requirements and Next Steps\\n\\n\\n\\nCredentialing\\nMembership\\nEnterprise\\nPARTNERSHIPS\\nTraining & Events\\n\\nResources\\n\\n\\n\\n\\n\\nJoin/Renew\\n\\nRenew\\nPROFESSIONAL JOIN\\nRECENT GRAD JOIN\\nSTUDENT JOIN\\n\\n\\n\\nAbout Us\\n\\nABOUT US HOME\\nWHO WE ARE\\nNEWSROOM\\nPARTICIPATE & VOLUNTEER\\nLEADERSHIP & GOVERNANCE\\nADVOCACY\\nISACA FOUNDATION\\nCONTACT US\\nCODE OF PROFESSIONAL ETHICS\\n\\n\\n\\nCAREERS\\n\\nCareer Center\\nCareers at ISACA\\n\\n\\n\\nSUPPORT\\n\\n\\nStore\\nTotal\\nView Cart Checkout\\nNo items have been added to your cart yet\\nBrowse Search\\n\\n\\nCart (0)\\n\\n\\nSign In\\n\\n\\nMEMBERSHIP\\n\\nCERTIFICATIONS\\nCERTIFICATES\\nCPE CERTIFICATES\\nEngage\\nLEARNING ACCESS\\nRESOURCES\\nORDER HISTORY\\nRedeemable Products\\n\\nSign Out\\n\\n\\nSign In\\n\\n\\nCreate an Account\\n\\n\\nCERTIFICATIONS\\n\\nCISA—Certified Information Systems Auditor\\nCISM—Certified Information Security Manager\\nCRISC—Certified in Risk and Information Systems Control\\nCDPSE—Certified Data Privacy Solutions Engineer\\nCGEIT—Certified in the Governance of Enterprise IT\\nCCOA—Certified Cybersecurity Operations Analyst\\nCET—Certified in Emerging Technology Certification\\nITCA—Information Technology Certified Associate\\nCSX-P—CSX Cybersecurity Practitioner Certification\\n\\n\\n\\nCERTIFICATES\\n\\nCCAK—Certificate in Cloud Auditing Knowledge\\nCOBIT\\nCOBIT 2019 Foundation\\nCOBIT 2019 Design & Implementation\\nImplementing the NIST Cybersecurity Framework using COBIT 2019\\nCOBIT 5 Certificates\\n\\n\\nCybersecurity Audit\\nCybersecurity Fundamentals\\nDigital Trust Ecosystem Framework Foundation Certificate\\nEmerging Technology\\nAI Fundamentals\\nBlockchain Fundamentals\\nCloud Fundamentals\\nIoT Fundamentals\\n\\n\\nInformation Technology\\nComputing Fundamentals\\nData Science Fundamentals\\nNetworks and Infrastructure Fundamentals\\nSoftware Development Fundamentals\\n\\n\\nIT Audit Fundamentals\\nIT Risk Fundamentals\\n\\n\\n\\nWHICH CERTIFICATION IS RIGHT FOR YOU?\\n\\n\\nRENEW A CERTIFICATION\\n\\n\\nMAINTAIN A CERTIFICATION\\n\\n\\nVERIFY A CERTIFICATION\\n\\n\\nDIGITAL BADGES\\n\\n\\nWhich Exam Prep is Right for You?\\n\\nTRAIN YOUR WAY WITH OFFICIAL ISACA EXAM PREP\\n\\nBUILD YOUR TEAM'S PERFORMANCE WITH CUSTOMIZED TRAINING\\n\\n\\nBECOME A MEMBER\\n\\nBrowse Chapters\\nFind Your Membership Type\\nMember Benefits\\n\\n\\n\\nENGAGE ONLINE COMMUNITY\\n\\n\\nGET INVOLVED\\n\\nAdvocacy\\nAuthor an Article\\nChapter Events Calendar\\nISACA Awards\\nSheLeadsTech\\nSpeak at Conferences\\nVolunteer\\nWrite an Exam Question\\n\\n\\n\\nMAXIMIZE YOUR MEMBERSHIP\\n\\nCareer Center\\nDiscounts & Savings\\nFree CPE\\nFree Resource Previews\\nMember-Exclusive Speaker Series\\nMentorship\\n\\n\\n\\nPersonalize Your Experience\\n\\n\\nUPDATE YOUR PROFILE\\n\\n\\nCMMI PERFORMANCE IMPROVEMENT SOLUTIONS\\n\\nCMMI Performance Solutions\\nCMMI Cybermaturity Platform\\nVoluntary Improvement Program\\n\\n\\n\\nENTERPRISE TRAINING & CREDENTIALS\\n\\nISACA Credentials\\nCMMI Training\\n\\n\\n\\nCMMI APPRAISALS (PARS)\\n\\n\\nENTERPRISE SUPPORT\\n\\n\\nCONTACT US\\n\\n\\nEmpower Your Team to Power Business Growth\\n\\n\\nCUSTOMIZE YOUR IT TEAM TRAINING\\n\\n\\nBECOME A TRAINING PARTNER\\n\\n\\nBECOME A CMMI PARTNER\\n\\n\\nBECOME AN ACADEMIC OR WORKFORCE PARTNER\\n\\n\\nSponsorship\\n\\nBecome a Sponsor\\nGlobal Sponsors\\n\\n\\n\\nFIND A TRAINING PARTNER\\n\\nCertification Training Partners\\nCertification Training Partners\\nAmericas\\nAsia and Oceania\\nChina\\nEMEA\\n\\n\\nCOBIT Training Partners\\nAcademic & Workforce Partners\\nCMMI Performance Improvement Partners\\n\\n\\n\\nOver 100,000 People Were Trained by ISACA in 2022\\n\\n\\nBECOME A PARTNER TO CAPITALIZE ON THIS HIGH DEMAND\\n\\n\\nCONFERENCES\\n\\nGRC Conference\\nISACA Europe Conference\\nISACA North America Conference\\nISACA Virtual Conference\\n\\n\\n\\nCHAPTER EVENTS\\n\\n\\nTraining Week\\n\\n\\nTRAIN YOUR WAY\\n\\nAll Training Types\\nOnline Review Courses\\nSession Recordings\\nWebinars\\nVirtual Summits\\n\\n\\n\\nGROUP/ENTERPRISE TRAINING\\n\\n\\nTRAINING FROM AN ACCREDITED PARTNER\\n\\n\\nTRAINING BY TOPIC\\n\\nAll Training Topics\\nArtificial Intelligence\\nCybersecurity\\nIT Audit\\nCertification Exam Preparation\\nCOBIT\\n\\n\\n\\nOn-Demand CPE Training\\n\\n\\nReady to Take Your AI Knowledge to the Next Level?\\n\\n\\nBROWSE ISACA’S NEW AI TRAINING COURSES\\n\\n\\nDIGITAL TRUST\\n\\n\\nISACA JOURNAL\\n\\n\\nINSIGHTS & EXPERTISE\\n\\n\\nNEWS & TRENDS\\n\\n\\nENGAGE ONLINE COMMUNITIES\\n\\n\\nCOBIT\\n\\n\\nRESOURCES BY TOPIC\\n\\nArtificial Intelligence\\nCybersecurity\\nEmerging Technology\\nGovernance\\nIT Audit\\nIT Risk\\nPrivacy\\n\\n\\n\\nFRAMEWORKS, STANDARDS AND MODELS\\n\\n\\nISACA NOW BLOG\\n\\n\\nISACA VIDEOS\\n\\n\\nISACA PODCAST\\n\\n\\nGLOSSARY\\n\\n\\nAnnouncing ISACA’s Digital Trust Ecosystem Framework and Portfolio\\n\\n\\nAdvance Digital Trust\\n\\n\\nCredentialing\\n\\nCREDENTIALING\\nCERTIFICATIONS\\nCERTIFICATIONS\\nCISA—Certified Information Systems Auditor\\nCISM—Certified Information Security Manager\\nCRISC—Certified in Risk and Information Systems Control\\nCDPSE—Certified Data Privacy Solutions Engineer\\nCGEIT—Certified in the Governance of Enterprise IT\\nCCOA—Certified Cybersecurity Operations Analyst\\nCET—Certified in Emerging Technology Certification\\nITCA—Information Technology Certified Associate\\nCSX-P—CSX Cybersecurity Practitioner Certification\\n\\n\\nCERTIFICATES\\nCERTIFICATES\\nCCAK—Certificate in Cloud Auditing Knowledge\\nCOBIT\\nCOBIT 2019 Foundation\\nCOBIT 2019 Design & Implementation\\nImplementing the NIST Cybersecurity Framework using COBIT 2019\\nCOBIT 5 Certificates\\n\\n\\nCybersecurity Audit\\nCybersecurity Fundamentals\\nDigital Trust Ecosystem Framework Foundation Certificate\\nEmerging Technology\\nAI Fundamentals\\nBlockchain Fundamentals\\nCloud Fundamentals\\nIoT Fundamentals\\n\\n\\nInformation Technology\\nComputing Fundamentals\\nData Science Fundamentals\\nNetworks and Infrastructure Fundamentals\\nSoftware Development Fundamentals\\n\\n\\nIT Audit Fundamentals\\nIT Risk Fundamentals\\n\\n\\nWHICH CERTIFICATION IS RIGHT FOR YOU?\\nRENEW A CERTIFICATION\\nMAINTAIN A CERTIFICATION\\nVERIFY A CERTIFICATION\\nDIGITAL BADGES\\nTRAIN YOUR WAY WITH OFFICIAL ISACA EXAM PREP\\nBUILD YOUR TEAM'S PERFORMANCE WITH CUSTOMIZED TRAINING\\n\\n\\nMembership\\nMEMBERSHIP\\nBECOME A MEMBER\\nBECOME A MEMBER\\nBrowse Chapters\\nFind Your Membership Type\\nMember Benefits\\n\\n\\nENGAGE ONLINE COMMUNITY\\nMAXIMIZE YOUR MEMBERSHIP\\nMAXIMIZE YOUR MEMBERSHIP\\nCareer Center\\nDiscounts & Savings\\nFree CPE\\nFree Resource Previews\\nMember-Exclusive Speaker Series\\nMentorship\\n\\n\\nUPDATE YOUR PROFILE\\nGET INVOLVED\\nGET INVOLVED\\nAdvocacy\\nAuthor an Article\\nChapter Events Calendar\\nISACA Awards\\nSheLeadsTech\\nSpeak at Conferences\\nVolunteer\\nWrite an Exam Question\\n\\n\\n\\n\\nEnterprise\\nENTERPRISE\\nCMMI PERFORMANCE IMPROVEMENT SOLUTIONS\\nCMMI PERFORMANCE IMPROVEMENT SOLUTIONS\\nCMMI Performance Solutions\\nCMMI Cybermaturity Platform\\nVoluntary Improvement Program\\n\\n\\nCUSTOMIZE YOUR IT TEAM TRAINING\\nENTERPRISE TRAINING & CREDENTIALS\\nENTERPRISE TRAINING AND CREDENTIALS\\nISACA Credentials\\nCMMI Training\\n\\n\\nCMMI APPRAISALS (PARS)\\nENTERPRISE SUPPORT\\nCONTACT US\\n\\n\\nPARTNERSHIPS\\nPARTNERSHIPS\\nBECOME A TRAINING PARTNER\\nBECOME A CMMI PARTNER\\nBECOME AN ACADEMIC OR WORKFORCE PARTNER\\nSponsorship\\nBecome a Sponsor\\nGlobal Sponsors\\n\\n\\nFIND A TRAINING PARTNER\\nFIND A TRAINING PARTNER\\nCertification Training Partners\\nCertification Training Partners\\nAmericas\\nAsia and Oceania\\nChina\\nEMEA\\n\\n\\nCOBIT Training Partners\\nAcademic & Workforce Partners\\nCMMI Performance Improvement Partners\\n\\n\\nBECOME A PARTNER TO CAPITALIZE ON THIS HIGH DEMAND\\n\\n\\nTraining & Events\\nTRAINING AND EVENTS\\nCONFERENCES\\nCONFERENCES\\nGRC Conference\\nISACA Europe Conference\\nISACA North America Conference\\nISACA Virtual Conference\\n\\n\\nCHAPTER EVENTS\\nTraining Week\\nTRAIN YOUR WAY\\nTRAIN YOUR WAY\\nAll Training Types\\nOnline Review Courses\\nSession Recordings\\nWebinars\\nVirtual Summits\\n\\n\\nGROUP/ENTERPRISE TRAINING\\nTRAINING FROM AN ACCREDITED PARTNER\\nTRAINING BY TOPIC\\nFind Training by Topic\\nAll Training Topics\\nArtificial Intelligence\\nCybersecurity\\nIT Audit\\nCertification Exam Preparation\\nCOBIT\\n\\n\\nOn-Demand CPE Training\\nBROWSE ISACA’S NEW AI TRAINING COURSES\\n\\n\\n\\nResources\\n\\nRESOURCES\\nDIGITAL TRUST\\nISACA JOURNAL\\nINSIGHTS & EXPERTISE\\nNEWS & TRENDS\\nENGAGE ONLINE COMMUNITIES\\nCOBIT\\nRESOURCES BY TOPIC\\nArtificial Intelligence\\nCybersecurity\\nEmerging Technology\\nGovernance\\nIT Audit\\nIT Risk\\nPrivacy\\n\\n\\nFRAMEWORKS, STANDARDS AND MODELS\\nISACA NOW BLOG\\nISACA VIDEOS\\nISACA PODCAST\\n\\nGLOSSARY\\n\\n\\nAdvance Digital Trust\\n\\nJoin/Renew\\nRenew\\nPROFESSIONAL JOIN\\nRECENT GRAD JOIN\\nSTUDENT JOIN\\nAbout Us\\nABOUT US HOME\\nWHO WE ARE\\nNEWSROOM\\nPARTICIPATE & VOLUNTEER\\nLEADERSHIP & GOVERNANCE\\nADVOCACY\\nISACA FOUNDATION\\nCONTACT US\\nCODE OF PROFESSIONAL ETHICS\\nCAREERS\\nCareer Center\\nCareers at ISACA\\nSUPPORT\\nStore\\nCart\\n\\n\\n\\nSign In\\nHome / Resources / White Papers / 2024 / Understanding the EU AI Act\\n\\n\\n\\n\\nCopy Link\\n\\n\\nShare on LinkedIn\\n\\n\\nShare on Facebook\\n\\n\\nShare on Twitter\\n\\n\\nShare via Email\\n\\n\\n\\nRead Time: 30 minutes\\nWhite Paper | 18 October 2024\\nUnderstanding the EU AI Act: Requirements and Next Steps\\nThe rapid growth in the use of artificial intelligence (AI) technologies, especially generative AI (genAI), is driven by the myriad benefits these technologies are purported to provide. But in the interest of maximizing efficiency, some enterprises have rushed to adopt AI without considering its risk and the harms it could cause. The EU AI Act puts requirements in place for certain AI systems used in the European Union and bans certain AI uses. This white paper explores the AI Act’s scope and risk categorization method, in addition to providing high-level overview of the requirements stipulated in the regulation. It also contains next steps for practitioners looking to be compliant with the Act.\\nEU AI Act FAQs\\nIntroduction\\nThe adoption of AI technologies has skyrocketed in the last few years. In 2019, 58% of organizations used AI for at least one business function; by 2024, that number jumped to 72%.1 The use of genAI nearly doubled from 2023 to 2024, going from just 33% to 65%.2\\nWhile the adoption of AI can help enterprises operate more efficiently, there is significant risk associated with it. Numerous lawsuits have been brought against genAI companies due to alleged copyright violations.3 Faulty AI or AI misuse can result in safety concerns, e.g., self-driving cars that have been tampered with, resulting in injury or death. AI systems trained on biased data could produce biased outcomes. Liability around AI remains murky, and it is often unclear who is ultimately accountable for harm caused by AI outputs.\\nThe EU AI Act, which was approved by the European Parliament on 13 March 2024 and by the EU Council on 21 May 2024, could help mitigate some of the risk associated with AI, allowing enterprises to use AI technologies in a safe, ethical, and responsible way and instilling confidence in AI systems. The Act is touted as the first comprehensive AI law in the world.4 Given the broad and thorough nature of the Act, it is possible that future AI laws and regulations could be modeled off the EU AI Act, similar to what happened with the EU’s General Data Protection Regulation (GDPR).\\nThe EU AI Act, which was approved by the European Parliament on 13 March 2024 and by the EU Council on 21 May 2024, could help mitigate some of the risk associated with AI, allowing enterprises to use AI technologies in a safe, ethical, and responsible way and instilling confidence in AI systems.\\nWhile not every enterprise around the world will need to be compliant with the EU AI Act, it is worthwhile to know the key requirements of the Act. The risk classification outlined in the Act can help enterprises think about the AI products they use and understand the risk associated with them.\\nKey Obligations of the EU AI Act\\nThe EU AI Act has many layers of compliance requirements, including at the AI use case, model, system, project, and enterprise levels. These requirements may vary depending on whether the enterprise is a provider, deployer, importer, or distributor and whether the AI is high-risk, limited-risk, a general-purpose AI model, or some combination. The following is a high-level overview of some of the key requirements of the EU AI Act.\\nDefinitions and Scope\\nThe Act thoroughly covers what is considered an AI system. Figure 1 shows some of the key characteristics of AI systems under the EU AI Act.5\\nFigure 1: Characteristics of AI Systems\\n\\nThe AI Act defines a risk as the combination of the probability of a harm occurring and the severity of the harm. It is crucial to understand the various roles as defined in the Act (figure 2).\\nFigure 2: Key Roles in EU AI Act\\nProvidersNatural or legal persons, public authorities, agencies, or other bodies that develop or have developed an artificial intelligence (AI) system or general-purpose AI model that is placed on the EU market. This applies to both free and paid AI systems.Product manufacturersEntities that manufacture products that incorporate AI systems.DeployersA natural or legal person, public authority, agency, or other body using an AI system, except if the system is being used for a personal, nonprofessional activity. (The majority of organizations subject to the EU AI Act will be deployers.)ImportersA natural or legal person located or established in the European Union who places an AI system that has the name or trademark of a natural or legal person established in a third country on the market in the European Union.DistributorsNatural or legal persons in the supply chain—other than the provider or importer—who make an AI system available in the EU market.\\nNote that enterprises may have a variety of roles based on the use case in question, e.g., an enterprise may be a deployer if using a third-party customer service chatbot but a provider of an AI-powered image editor. It is important to identify the applicable role based on the use case as requirements may differ for providers, deployers, and distributors.\\nThe AI Act stipulates requirements for AI systems that are placed on the market in the European Union. The Act defines placing AI on the market as the first availability of an AI system or a general-purpose AI model on the EU market. Making AI available on the market refers to the use of an AI system or general-purpose AI model for distribution or use in the European Union through a commercial activity, which may be paid or free. Putting AI into service refers to the first use of an AI system that is supplied directly to the deployer for use in the European Union for an intended purpose.6\\nMaking AI available on the market refers to the use of an AI system or general-purpose AI model for distribution or use in the European Union through a commercial activity, which may be paid or free. Putting AI into service refers to the first use of an AI system that is supplied directly to the deployer for use in the European Union for an intended purpose.\\nWithin the European Union, the AI Act applies to:7\\n\\nProviders placing AI systems on the market in the European Union\\nAI system deployers that are established or located in the European Union\\nAI system importers and distributors\\nProduct manufacturers that are putting their product and an AI system together on the market or into service in the European Union\\nAuthorized representatives of providers that are not established in the European Union\\nAffected persons located in the European Union\\n\\nOutside the European Union, the Act applies to:\\n\\nProviders placing AI systems on the market in the European Union, regardless of where the providers are located\\nAI system providers and deployers outside of the European Union whose AI output is used in the European Union\\n\\nBecause of this wide scope, providers and deployers could be subject to the AI Act even if they are not located in the European Union. Given the extraterritorial scope of the regulation, it is crucial that all enterprises determine if the Act’s requirements apply to them.\\nExceptions to the AI Act\\nThe EU AI Act does not apply to all AI systems on the market in the European Union. AI systems intended for military, defense, or national security activities are excluded, even if used by a private entity. But if those systems are, even temporarily, used for other purposes, they would be subject to the regulation.\\nThe AI Act is also not applicable to AI systems used solely for scientific research and development, but there are requirements for AI systems or models that need to be tested in real-world conditions.8\\nProhibited Systems\\nCertain AI practices that are deemed too risky are banned by the AI Act. Figure 3 indicates these practices. Prohibited systems are those that could cause significant harm to individuals; these practices could result in privacy violations, discrimination, and limitations of individual freedom. AI systems that are used for the purposes outlined in figure 3 may not, barring certain narrow exceptions, be placed on the market or used in the European Union.9\\nFigure 3: AI Practices Prohibited by the EU AI Act\\n| Banned AI Practice\\n |\\n| --- |\\n| Artificial intelligence (AI) systems that subliminally or intentionally use manipulative/deceptive techniques to affect the behavior of a person or group of people by affecting their capability to make an informed decision, resulting in them making a decision that they would not have made otherwise or that may cause themselves or others significant harm\\n|\\n| AI systems that exploit a person’s or persons’ vulnerabilities, e.g., due to age or disability, to distort the behavior of that individual in a way that could cause that person or someone else significant harm\\n|\\n| AI systems that provide a social score on individuals based on their social behavior or personality that leads to detrimental or unfavorable treatment of individuals\\n|\\n| AI systems that use profiling to predict the risk of a person to commit a crime\\n|\\n| AI systems that scrape CCTV or the Internet to build a facial recognition database\\n|\\n| AI systems that aim to detect a person’s emotions in the workplace or in educational institutions\\n|\\n| Biometric AI categorization systems that label people based on biometric information to determine their race, political beliefs, trade union membership, religious/philosophical beliefs, or sex life/sexual orientation\\n|\\n| AI systems that leverage real-time biometric identification in public places for law enforcement purposes (some exceptions apply, e.g., for victims of abduction, prevention of imminent threats to life, etc.)\\n|\\nHigh-Risk AI Systems\\nMuch of the EU AI Act focuses on the obligations for high-risk AI systems. In contrast to prohibited AI systems, high-risk AI systems may be placed on the market in the European Union, provided that several requirements are met. The obligations for high-risk systems apply to:10\\n\\nAI systems that are a safety component of a product\\nBiometrics\\nCritical infrastructure, e.g., water supply\\nEducation and job training, e.g., admission, cheating detectors\\nEmployment and employee management\\nEssential public services and benefits, e.g., emergency services\\nLaw enforcement\\nImmigration and border management\\nJudicial and democratic processes\\n\\nThese systems are not considered high-risk in cases where the system does not pose a significant risk of harm to the health, safety, or fundamental rights of individuals, or influence the decision making of individuals.\\nThe following are key obligations for providers of high-risk AI systems.\\nRisk Management\\nA risk management system is required for high-risk AI systems. The risk management process, which should span the entire life cycle of the AI system, must be iterative and updated as necessary. Figure 4 shows the risk management steps required by the EU AI Act. The risk management system must also factor in whether any of the risk will affect people under the age of 18 or other vulnerable groups.11\\nFigure 4: Risk Management Steps\\n\\nHigh-risk AI systems should be designed and tested to validate that they are compliant and to help determine optimal risk management measures. This should be an iterative process; because AI systems can evolve and the ways in which they are used can also change, validating compliance and reevaluating risk management measures cannot be a one-time activity.\\nQuality Management System\\nUnder the AI Act, providers of high-risk AI systems must have a quality management system in place to help ensure compliance. It should be comprised of written policies, procedures, and instructions. The quality management system should account for:12\\n\\nConformity assessment procedures\\nProcedures for modifications to the high-risk system\\nProcedures and techniques for the design, development, quality control, and quality assurance of the high-risk AI system\\nTest and validation procedures throughout the development life cycle of the high-risk AI system\\nData management systems and procedures\\nThe risk management system\\nThe postmarket monitoring system\\nProcesses around the reporting of serious incidents\\nCommunication processes\\nRecordkeeping systems and processes\\nResource management\\nA framework outlining relevant responsibilities and corresponding accountability\\n\\nData and Data Governance\\nGiven that high-quality data is a prerequisite for effective and ethical AI models, the EU AI Act has several requirements around data and data governance for high-risk AI systems. Data sets should contain accurate information, and potential bias must be identified and mitigated as well as possible. These requirements apply to training data, validation data, and testing data.13\\nFigure 5 shows the dimensions of data quality that should be considered.\\nFigure 5: Dimensions a Data Quality Plan Can Measure\\n| Data Terminology\\n | Measure\\n|\\n| --- | --- |\\n| Accuracy\\n| Is the data true to original intent? Is it precise?\\n|\\n| Completeness\\n| Are all required data attributes captured?\\n|\\n| Coverage\\n| Are needed data records available?\\n|\\n| Conformity\\n| Does the data align to required standards?\\n|\\n| Consistency\\n| Does the data adhere to any internally or externally mandated patterns? Is it uniform?\\n|\\n| Duplication\\n| Are the data records or attributes redundant?\\n|\\n| Relational Integrity\\n| Are data relationships (e.g., parent and child links) accurate?\\n|\\n| Timeliness\\n| Is the data current and available for use when needed?\\n|\\n| Uniqueness\\n| Is the data unique or are there duplicates?\\n|\\nSource: ISACA, Applied Data Management for Privacy, Security and Digital Trust, 2023\\nWhile it is important to maintain data quality, the EU AI Act has also stressed the need for well-defined and well-documented data collection and data preparation processing operations (e.g., annotation, labelling, cleaning, enrichment, and aggregation) covering different stages of the data life cycle.\\nAccuracy, Robustness, and Cybersecurity\\nThe EU AI Act requires accuracy, robustness, and cybersecurity measures for high-risk AI systems. Technical and organizational measures for resiliency purposes must be in place. Backups, redundancy solutions, and fail-safe plans may be used to support robustness.\\nHigh-risk AI systems that continue to learn after being put into service should be designed to reduce or eliminate the risk of biased outputs that influence future operations. This may include AI systems that are open source, leverage reinforcement learning from human feedback, or use retrieval augmented generation. Mitigation measures should be in place to address feedback loops.\\nHigh-risk AI systems that continue to learn after being put into service should be designed to reduce or eliminate the risk of biased outputs that influence future operations.\\nAdditionally, the Act requires resilience against unauthorized attempts to alter system use, outputs, or performance. There must be appropriate technical solutions in place to ensure the cybersecurity of high-risk AI systems. This should include measures to prevent, detect, respond to, resolve, and control for data poisoning, model poisoning, model evasion, and adversarial attacks.14\\nTechnical Documentation, Recordkeeping, and Transparency\\nDemonstrating compliance for high-risk AI systems is mandatory under the EU AI Act, and it requires technical documentation for these systems before they are placed on the market or put into service.15 This technical documentation can address the black-box nature of some AI systems and can help enterprises respond when AI systems do not operate as desired. The technical documentation requirements include:16\\n\\nA description of the AI system, e.g., its intended purpose, how it interacts with hardware and software, and instructions for use for a deployer\\nA detailed explanation of the elements of the AI system and the process of its development, e.g., how the system was designed and testing and cybersecurity measures in place\\nA detailed explanation of the data used in the AI system, e.g., the data requirements affecting the nature, limitations, or other factors of the data; training data sets used and their provenance, scope, and main characteristics; procedures for how the data was obtained and selected; labelling (e.g., for supervised learning); and data cleaning methodologies, including outlier detection\\nAn explanation of the monitoring, functioning, and control of the system\\nRelevant performance metrics\\nThe risk management system\\nProvider changes to the system through its life cycle\\nA declaration of conformity\\nA list of any harmonized standards applied\\nA description of the postmarket monitoring plan\\n\\nIn addition to technical documentation, high-risk AI systems must have automatic logs over the lifetime of the system. This recordkeeping can help ensure traceability of AI systems and assist with postmarket monitoring activities. The recordkeeping must include the start and end date and time for each use, the input data and reference database against which it was checked, and the identification of people involved in the verification of the results.17\\nTechnical documentation and recordkeeping ultimately facilitate transparency about how high-risk AI systems operate and the impacts of their operation. One transparency requirement in the EU AI Act is that providers must include instructions for using the high-risk AI system in a safe manner. This should include an overview of human oversight measures, any maintenance the system may require, and the anticipated lifespan of the system.\\nTechnical documentation and recordkeeping ultimately facilitate transparency about how high-risk AI systems operate and the impacts of their operation.\\nPostmarket Monitoring\\nGiven that many AI systems can evolve even after they are placed on the market, monitoring them after deployment is crucial to ensure ongoing compliance. The EU AI Act requires that providers of high-risk AI systems use a postmarket monitoring system to collect and review information relevant to the performance of the AI system so they can identify any need to immediately apply a corrective or preventative action. They must also ensure that a process is in place to report any serious incidents to relevant authorities. Postmarket monitoring should account for instances where the high-risk AI system interacts with other AI systems.18\\nConformity Assessments\\nConformity assessments show that high-risk AI systems are compliant with applicable regulations. They will assess the quality management system and technical documentation. These assessments are required for high-risk AI systems, and new assessments must occur after any substantial modification to these systems.19\\nHigh-risk AI systems that meet conformity assessment requirements will receive a CE marking—a physical marking for physical products, a digital one for products that are only digital. High-risk AI systems with the CE marking may be placed on the EU market.\\nHuman Oversight\\nConsidering the potential harm that high-risk AI systems could cause, the EU AI Act requires human oversight for these systems. The goal of human oversight is to reduce the risk to health, safety, or fundamental rights that could result from the use of high-risk AI systems. The nature of the oversight needed may vary depending on the risk, degree of system autonomy, and context in which a system is used.\\nConsidering the potential harm that high-risk AI systems could cause, the EU AI Act requires human oversight for these systems. The goal of human oversight is to reduce the risk to health, safety, or fundamental rights that could result from the use of high-risk AI systems.\\nHuman oversight should:20\\n\\nHelp deployers understand the abilities and limitations of the high-risk AI system\\nBring attention to the possibility of overreliance on outputs of high-risk AI systems, especially those that provide information or decision recommendations\\nAllow for the correct interpretation of the system’s output\\nEnable the choice to disregard, override, or reverse the system’s output\\nAllow for humans to intervene or stop the system’s operation\\n\\nAI Literacy\\nTo maximize the value AI provides and minimize the potential harm, promoting AI literacy is essential. AI literacy refers to the knowledge and understanding required to effectively use, interact with, and critically evaluate AI systems. This includes a basic understanding of AI, technical skills, ethical and legal awareness, critical thinking, and practical application. AI literacy is crucial during all phases of the AI life cycle. The EU AI Act requires providers and deployers of AI systems (regardless of the level of risk) to ensure that anyone dealing with the operation and use of AI systems on their behalf should have a sufficient level of AI literacy.21 AI literacy can ultimately facilitate human oversight of AI systems.\\nAI literacy refers to the knowledge and understanding required to effectively use, interact with, and critically evaluate AI systems.\\nRegistration\\nBefore being placed on the market or put into service, high-risk systems must be registered with the EU database for high-risk AI systems.22 This database will contain information that is accessible and publicly available. Information for the database must be user-friendly and machine-readable.\\nReporting Serious Incidents\\nThe EU AI Act requires that high-risk AI system providers report serious incidents when they occur. The Act defines serious incidents as an AI system malfunction or incident that leads to death or harm to a person’s health, serious and undoable disruption to critical infrastructure, not meeting obligations intended to protect fundamental rights, or serious harm to property or the environment.\\nThe EU AI Act requires that high-risk AI system providers report serious incidents when they occur. The Act defines serious incidents as an AI system malfunction or incident that leads to death or harm to a person’s health, serious and undoable disruption to critical infrastructure, not meeting obligations intended to protect fundamental rights, or serious harm to property or the environment.\\nReports of this type are made to the market surveillance authorities of the Member State or States of the European Union where the incident happened. An incident must be reported no later than 15 days after becoming aware of it, but depending on the severity of the incident’s impact, the reporting time may be less.\\nAfter the incident is reported, the provider must investigate the incident, including making a risk assessment, and apply the appropriate corrective action.23\\nRequirements for Deployers of High-Risk Systems\\nEnterprises deploying high-risk AI systems, models, or services have certain obligations under the EU AI Act.24 Due diligence is crucial when selecting an AI system provider as deployers may be liable for providers’ shortcomings. Figure 6 outlines the obligations of high-risk AI system deployers.\\nFigure 6: Obligations for Deployers of High-Risk AI Systems\\n\\nDue diligence is crucial when selecting an AI system provider as deployers may be liable for providers’ shortcomings.\\nTransparency Requirements\\nThe EU AI Act includes transparency requirements for the providers and deployers of certain types of AI systems. These requirements are not specific to high-risk AI systems. Transparency about the use of AI is critical to ensuring that people trust AI, and it can affect the way in which they interact with AI. Under the EU AI Act, people interacting with AI systems must be notified that they are interacting with AI. For example, people seeking customer service support who are encouraged to talk with a chatbot must be notified that they are not speaking with a human.\\nTransparency about the use of AI is critical to ensuring that people trust AI, and it can affect the way in which they interact with AI.\\nAdditionally, providers of AI systems that create synthetic content must ensure that outputs are marked as artificially generated or manipulated. Providers must consider technical limitations and capabilities of this marking, and being informed of what is considered state-of-the-art in this field is important.25 Watermarking AI-generated or -manipulated content can help mitigate the harm spread by deepfakes and limit the proliferation of misinformation and disinformation.\\nThere are also transparency requirements for deployers of limited-risk AI systems that have emotion recognition or biometric categorization features; these deployers must notify people affected by these systems about their operation. Note that this type of sensitive personal data may also be subject to other EU regulations, e.g., GPDR.\\nGeneral-Purpose AI Models\\nThe EU AI Act considers general-purpose AI models to be AI models that can perform a variety of distinct tasks and that display generalities. Through self-supervised, unsupervised, or reinforcement learning, these models are trained on a large quantity of data. General-purpose AI models may be refined and modified into new models. The EU AI Act imposes many obligations for providers of general-purpose AI models. They must create and maintain the models’ technical documentation, including training and testing processes, and this information should be made available to AI system providers who plan to incorporate the general-purpose AI models into their AI systems. Model providers must also create a detailed summary of the content that trained the general-purpose AI model, and this information must be made publicly available.26\\nThe EU AI Act also outlines additional obligations for providers of general-purpose AI models with systemic risk. General-purpose AI models with systemic risk are those that have high-impact capabilities, based on various indicators and benchmarks defined in the Act.27 Systemic risk is defined as risk that could impact public health, safety, security, fundamental rights, or society as a whole and can be disseminated at scale across the value chain. Given that it may be easier to grasp the full capabilities of a model after it is on the market and has been used more, the threshold for what classifies as an AI model with systemic risk is not a fixed point. For this reason, providers may need to reevaluate their general-purpose AI models periodically.28\\nProviders of general-purpose AI models with systemic risk must meet all the requirements of providers of general-purpose AI models outlined previously. Those who provide general-purpose AI models with systemic risk must also evaluate the model and conduct adversarial testing to identify and mitigate systemic risk associated with it; report any serious incidents and corresponding remediation to the AI Office (a group established at the EU level); and provide sufficient cybersecurity protection for the model.\\nInnovation Consideration\\nMany AI use cases are new, and AI system capabilities are evolving rapidly. The Act recognizes that the regulations it embodies may be criticized for stifling innovation. To remedy that, the Act requires that each Member State create an AI regulatory sandbox to foster innovation and facilitate the development, testing, and validation of cutting-edge AI systems before they are placed on the market.29\\nPenalties\\nConsequences for noncompliance with the EU AI Act vary based on the nature of the noncompliance. Noncompliance with banned AI practices is subject to fines up to €35,000,000 or up to 7% of the company’s total global annual turnover, whichever is higher. Noncompliance with other provisions of the Act is subject to fines of up to €15,000,000 or up to 3% of total global annual turnover, whichever is higher. For small to medium-sized enterprises, the fines are not as severe; they are up to the previously stated percentages or amounts, whichever is lower.\\nNoncompliance with banned AI practices is subject to fines up to €35,000,000 or up to 7% of the company’s total global annual turnover, whichever is higher.\\nEnterprises must supply accurate and up-to-date information to relevant authorities as necessary. Providing inaccurate, incomplete, or misleading information is subject to a fine of up to €7,500,000 or 1% of global annual turnover, whichever is higher.\\nNatural or legal persons can file complaints about noncompliance with the Act to the appropriate market surveillance authority.30\\nNext Steps for Practitioners\\nThere are numerous requirements for enterprises affected by the EU AI Act. Given the consequences of noncompliance, enterprises that must be compliant with the regulation should begin working toward compliance immediately.\\nTimeline\\nThe EU AI Act entered into force on 1 August 2024, and much of it will apply beginning 2 August 2026. Figure 7 shows a timeline of the AI Act.31\\nFigure 7: EU AI Act Timeline\\n\\nPrivacy Input\\nBecause of the many similarities between privacy regulations and AI-related regulations, an enterprise’s privacy officers along with legal and compliance teams will have insight on whether the EU AI Act applies to the enterprise and how it may impact AI development and/or deployment. If it does, the team developing AI should work closely with their privacy, legal, and compliance colleagues to understand their obligations under the EU AI Act.\\nMany of the requirements under the Act exist today under GDPR, so enterprises will benefit heavily from taking cues from their privacy officers when it comes to areas such as risk management, data governance, recordkeeping, accuracy and robustness, human oversight and transparency. The privacy function is used to dealing with transparency, ethics, risk assessments, and accountability, where trust is key.\\nMoreover, AI systems require data, including personal data, which means that GDPR will apply concurrently with the EU AI Act. In addition, it is often difficult to separate personal data from nonpersonal data. This means that ensuring lawful use of the data feeding the AI model is key. In particular, there needs to be lawful grounds for using the personal data (e.g., formal consent or another type of permission granted); again, the privacy officer will be a key person involved in guiding the enterprise toward compliance with the EU AI Act. Note that collaboration with key stakeholders (e.g., procurement, risk, business, security, human resources, and technical teams) on a regular basis is essential, as enforcement actions could impact the way AI systems are used or deployed.\\nLegal and compliance teams can help verify that external communication requirements are met. Collaborating with user experience personnel to develop these notices can provide consumers with information about AI use that is transparent and easy to understand.\\nEnterprises that are not subject to the AI Act can still implement parts of it in anticipation of wider global AI-related legislation.32 The risk-classification scheme in the Act can help enterprises classify the risk of the AI systems they use or create. Ensuring that AI systems do not cause harm can be valuable in building more trustworthy AI and is a worthwhile pursuit for all enterprises, not just those subject to the EU AI Act.\\nAI Inventory and Third-Party Management\\nTo work toward compliance with the EU AI Act, practitioners need to determine the AI systems their enterprises use, create, and deploy. Identifying these systems can mitigate the risk of shadow IT.\\nTo work toward compliance with the EU AI Act, practitioners need to determine the AI systems their enterprises use, create, and deploy. Identifying these systems can mitigate the risk of shadow IT.\\nNote that not all AI use will be subject to the EU AI Act or handled the same way under the Act. For example, as previously noted, an enterprise could be an AI provider in one case but a deployer in another. Regardless, enterprises should ensure that both they and any third parties they work with are compliant with the EU AI Act as appropriate. For example, if a marketing team leverages a third-party AI image generator, the enterprise would not be subject to provider requirements, but it should still ensure that the provider is compliant with the Act, for example, by verifying that AI-generated images have a watermark.\\nMany enterprises may have already done risk assessments of AI systems in their organization. It is important to remember that the way an enterprise has defined a high risk could differ from the EU AI Act’s definition. Enterprises subject to the Act should conduct risk assessment activities that align with the Act’s classification scheme.\\nDocument AI System Acquisition and Use Processes\\nIt is critical to have a process in place for acquisition of AI systems as well as their appropriate use. If AI is already in use, steps must be taken to ensure that it meets requirements; it is important that enterprises do not craft requirements based on existing AI systems and use cases already in place.\\nService-level agreements and vendor contracts should clearly outline whether and how AI is used. In each case, AI risk must be accounted for, especially in the procurement of AI software or services. There must also be a documented process in place for how third parties will notify their customers of AI-related incidents and outages.\\nEnterprises, regardless of their need to comply with the EU AI Act, must establish organizationwide policies for when AI may be used, when it may not be, and situations that require escalation. To address matters that are escalated and ensure a holistic approach to AI use, enterprises should consider establishing an AI governance committee, comprised of individuals from across the enterprise who can oversee AI use in the organization.\\nSome key considerations for enterprises beginning an AI program include:33\\n\\nTrust but verify—Given how AI systems operate, it is quite possible that not all of their outputs will be correct. Outputs should be validated for accuracy and checked for potential bias.\\nConsider existing compliance requirements—AI systems and models will likely use personal data, which means that applicable privacy regulations, e.g., GDPR, can apply alongside the EU AI Act.\\nRevise existing policies—AI systems can perform a variety of tasks, but not all use cases may be compliant with applicable laws and regulations or fall within an enterprise’s risk appetite. Leverage and update existing acceptable use policies or design a new one, if it does not exist.\\nAdapt existing cybersecurity and privacy policies and programs—Promote the use of security by design and privacy by design and default in AI system development. Thinking through security and privacy considerations before partnering with a third-party AI provider can help prevent downstream cyberrisk and privacy risk and could help address compliance requirements.\\nPromote AI literacy—Train and educate employees on AI technologies and risk. For instance, in certain cases, it may be worthwhile to provide departmental training on appropriate uses of AI specific to certain job roles, e.g., notifying a human resources department that, under the EU AI Act, they may not use AI tools to monitor employee happiness.\\nDesignate an AI lead—Someone must be tasked with tracking the AI tools in use and the enterprise’s broader approach to AI. AI leads should work closely with other relevant personnel in the enterprise, including cybersecurity, privacy, legal, procurement, risk, and audit staff.\\nPerform a cost analysis—Evaluate the cost of implementing AI systems along with any cost savings that these systems may provide.\\nInstitute audits and traceability—Given transparency and conformity assessment requirements in the EU AI Act, enterprises must ensure they understand how any AI models they create or use function. Data sources used to train AI models should be understood to help limit manipulation and mitigate against bias. Audits can provide insight into how AI systems work, helping enterprises meet transparency obligations.\\nDevelop AI ethical guidelines—Certain uses of AI may not be deemed ethical by an organization. For example, leveraging genAI to create content that customers must pay for may not be permitted. An enterprise’s ethical guidelines for AI use must be documented and shared throughout the organization. Note that these guidelines may need to change as AI use evolves and as liability and copyright laws change to keep up with the evolution of AI.\\nConsider societal impacts—The ways in which enterprises leverage AI could have significant effects on society. For example, there are understandable fears about job loss and job displacement. Deepfakes have also become quite persuasive, and people will need to be taught to identify AI-driven misinformation and disinformation. In the face of these challenges, enterprises should consider the broader social implications of their use of AI, for example by considering what the impact would be if every organization leveraged AI technology in a given manner.\\n\\nConclusion\\nThe benefits that AI systems can provide must be balanced with the risk they pose. The EU AI Act’s comprehensive risk-based approach to AI can help enterprises develop and deploy AI in a way that is safe, transparent, and trustworthy. Even enterprises not required to be compliant with the Act can implement parts of it as a best practice and in anticipation of future legislation by other jurisdictions.\\nThe capabilities of AI systems and the laws and regulations pertaining to them are rapidly evolving, and there are unknowns with AI systems and the law, e.g., liability in the event an AI system causes a harm. Developing and using compliant and trustworthy AI is an iterative process, not a one-time activity. Staying informed about AI, how it is being used, and its potential consequences is critical to maximizing its value and limiting its harm.\\nEndnotes\\n1 McKinsey & Company, “The State of AI in Early 2024: Gen AI Adoption Spikes and Starts to Generate Value,” 30 May 2024\\n2 McKinsey, “State of AI in Early 2024”\\n3 Lutkevich, B.; “AI Lawsuits Explained: Who’s Getting Sued?,” TechTarget, 25 June 2024\\n4 European Parliament, “EU AI Act: First Regulation on Artificial Intelligence,” 8 June 2023\\n5 Official Journal of the European Union, “REGULATION (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139, and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797, and (EU) 2020/1828 (Artificial Intelligence Act),” Article 2 and Article 3, 12 July 2024\\n6 European Union, “Artificial Intelligence Act,” Article 3\\n7 European Union, “Artificial Intelligence Act,” Article 2\\n8 European Union, “Artificial Intelligence Act,” Article 2\\n9 European Union, “Artificial Intelligence Act,” Article 5\\n10 European Union, “Artificial Intelligence Act,” Article 6 and Annex III\\n11 European Union, “Artificial Intelligence Act,” Article 9\\n12 European Union, “Artificial Intelligence Act,” Article 17\\n13 European Union, “Artificial Intelligence Act,” Article 10\\n14 European Union, “Artificial Intelligence Act,” Article 15\\n15 European Union, “Artificial Intelligence Act,” Article 11\\n16 European Union, “Artificial Intelligence Act,” Annex IV\\n17 European Union, “Artificial Intelligence Act,” Article 12\\n18 European Union, “Artificial Intelligence Act,” Recital 155 and Article 72\\n19 European Union, “Artificial Intelligence Act,” Article 43\\n20 European Union, “Artificial Intelligence Act,” Article 14\\n21 European Union, “Artificial Intelligence Act,” Article 4\\n22 European Union, “Artificial Intelligence Act,” Article 49, Article 71\\n23 European Union, “Artificial Intelligence Act,” Article 73\\n24 European Union, “Artificial Intelligence Act,” Article 26\\n25 European Union, “Artificial Intelligence Act,” Article 50\\n26 European Union, “Artificial Intelligence Act,” Article 53\\n27 European Union, “Artificial Intelligence Act,” Article 51\\n28 European Union, “Artificial Intelligence Act,” Article 55\\n29 European Union, “Artificial Intelligence Act,” Article 57\\n30 European Union, “Artificial Intelligence Act,” Article 99\\n31 European Union, “Artificial Intelligence Act,” Article 113\\n32 This situation may be similar to what happened with the GDPR, where the European Union seemed to lead the charge for data privacy, followed by many other countries.\\n33 ISACA, The Promise and Peril of the AI Revolution: Managing Risk, 12 September 2023\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContact Us\\n\\nTerms\\nPrivacy\\nCookie Notice\\nCookie Settings\\nFraud Reporting\\nBug Reporting\\n\\n1700 E. Golf Road, Suite 400, Schaumburg, Illinois 60173, USA\\xa0\\xa0|\\xa0\\xa0+1-847-253-1545\\xa0\\xa0|\\xa0\\xa0©2024 ISACA. All rights reserved.\\n \"}, {'title': 'A Primer on the EU AI Act - OpenAI', 'url': 'https://openai.com/global-affairs/a-primer-on-the-eu-ai-act/', 'content': 'The AI Act is built upon a risk-based framework, with specific requirements for high-risk and unacceptable-risk AI systems. The Act requires companies to classify the risk level of their AI systems to determine the corresponding regulatory obligations, and sets out various categories or tiers of AI systems that each carry different obligations.', 'score': 0.9242583, 'raw_content': 'A Primer on the EU AI Act: What It Means for AI Providers and Deployers | OpenAI\\nSkip to main content\\n\\n\\nResearch\\nProducts\\nSafety\\nCompany\\n\\nA Primer on the EU AI Act: What It Means for AI Providers and Deployers | OpenAI\\n\\nWhen will the AI Act apply?\\nWho is covered?\\nApplication to companies established outside the EU\\nRisk-Based Regulation\\nProhibited AI Practices\\nHigh-Risk AI Systems\\nMinimal or Minor-Risk AI Systems\\nGeneral Purpose AI (GPAI)\\nNext Steps and How to Prepare for Compliance\\n\\nPublished: July 30, 2024\\nA Primer on the EU AI Act\\nWe’re sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases\\nUpdate: On September 25, 2024, we signed up to the three core commitments in the EU AI Pact.\\n\\n\\nAdopt an AI governance strategy to foster the uptake of AI in the organization and work towards future compliance with the AI Act;\\n\\n\\ncarry out to the extent feasible a mapping of AI systems provided or deployed in areas that would be considered high-risk under the AI Act;\\n\\n\\npromote awareness and AI literacy of their staff and other persons dealing with AI systems on their behalf, taking into account their technical knowledge, experience, education and training and the context the AI systems are to be used in, and considering the persons or groups of persons affected by the use of the AI systems.\\n\\n\\nWe believe the AI Pact’s core focus on AI literacy, adoption, and governance targets the right priorities to ensure the gains of AI are broadly distributed. Furthermore, they are aligned with our mission to provide safe, cutting-edge technologies that benefit everyone.\\n\\nThe EU AI Act\\u2060(opens in a new window) is a significant regulatory framework designed to manage the development, deployment, and use of AI across Europe. It has a substantial focus on safety to promote trustworthy AI adoption in Europe while protecting health, safety, and fundamental rights. It introduces new requirements based on the risks associated with AI systems, with a particular focus on high-risk and unacceptable-use cases, as well as special obligations for general purpose AI (GPAI) models and systems.\\nWhile the legislative process is complete and the law will enter into force in August 2024, further guidance and implementing legislation will be required to define the scope of the law, especially as it applies to GPAI models like OpenAI’s.\\nAt OpenAI, we are committed to complying with the Act, not only because this is a legal obligation, but also because the goal of the law aligns with our mission to develop and deploy safe AI to benefit all of humanity. We are proud to release models that are industry leading on both capabilities and safety. We believe in a balanced, scientific approach where safety measures\\u2060 are integrated into the development process from the outset. Our teams span a wide spectrum of technical efforts tackling AI safety challenges including, evaluations of models under our Preparedness Framework\\u2060 prior to their deployment, internal and external red-teaming\\u2060, post-deployment monitoring\\u2060 for abuse, Bug Bounty\\u2060 and Cybersecurity Grant\\u2060 Programs, and contribution to authenticity standards\\u2060, among others.\\nWe will work closely with the EU AI Office and other relevant authorities as the new law is implemented in the coming months, and we hope that the expertise we’ve built will help advance the objectives of the Act when it comes to deploying safe and beneficial AI.\\nIn this post, we provide an overview of some key topics in the AI Act, with a special focus on prohibited and high-risk use cases.\\nWhen will the AI Act apply?\\nThe AI Act will enter into force on August 1, 2024, 20 days after publication in the EU Official Journal. While most of the Act’s provisions will not become effective for 24 months after entry into force, there are several important deadlines to keep in mind:\\n\\n\\nBans on prohibited practices will become effective 6 months after entry into force (February 2025)\\n\\n\\nCodes of practice, which will cover many of the implementation details needed to comply with the Act, will need to be finalized within 9 months after entry into force (May 2025)\\n\\n\\nMost general purpose AI obligations will become effective 12 months after entry into force (August 2025).\\n\\n\\nObligations for most high-risk AI systems apply 24 months after entry into force (August 2026).\\n\\n\\nPre-existing GPAI systems that have not been subject to a substantial modification, and certain AI systems that are components of large-scale IT systems identified in Annex X of the AI Act, will have a longer implementation deadline of 36 months (August 2027).\\nWho is covered?\\nThe AI Act principally applies to “AI systems,” which the Act defines as “a machine‑based system designed to operate with varying levels of autonomy, that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.”\\xa0 This definition is broadly consistent with the OECD’s definition of “AI systems” issued in 2023 and the definition used in the Biden Administration’s Executive Order 14110 on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.\\nImportantly, the AI Act differentiates between providers and deployers of AI systems. Providers are entities, like OpenAI, that develop an AI system or a general-purpose AI model. It also includes entities that have an AI system or a general-purpose AI model developed and place it on the market or who put the AI system into service under its own name or trademark, whether for payment or free of charge.\\nDeployers are customers or partners who use these systems or models in their own applications, such as integrating GPT-4o into a specific use case. Although the majority of obligations under the AI Act fall on providers rather than deployers, it’s important to note that a deployer that integrates an AI model into their own AI system can become a provider under the Act, such as by using their own trademark on an AI system or modifying the AI system in ways that weren’t intended by the provider.\\nApplication to companies established outside the EU\\nOrganizations outside the EU will still have to comply with the AI Act under a variety of conditions that can be quite wide-reaching.\\xa0 For example, the Act applies if:\\n\\n\\nA provider places an AI system or GPAI model on the EU market, regardless of whether the company is established in the EU or another country;\\n\\n\\nDeployers of an AI system have their place of establishment in or are located within the EU;\\n\\n\\nProviders and deployers of AI systems are established or located in a third country, but the output produced by the AI system is used within the EU.\\n\\n\\nThe broad extraterritorial reach of the AI Act means that non-European companies will need to comply with the Act to serve EU customers regardless of whether they are based inside the EU.\\nRisk-Based Regulation\\nThe AI Act is built upon a risk-based framework, with specific requirements for high-risk and unacceptable-risk AI systems. The Act requires companies to classify the risk level of their AI systems to determine the corresponding regulatory obligations, and sets out various categories or tiers of AI systems that each carry different obligations.\\nProhibited AI Practices\\nCertain AI practices that are deemed to pose an unacceptable risk to individuals’ rights are entirely prohibited. These practices include:\\n\\n\\nDeploying subliminal, manipulative, or deceptive techniques to distort behavior and impair informed decision-making, causing significant harm.\\n\\n\\nExploiting vulnerabilities related to age, disability, or socio-economic circumstances to distort behavior, causing significant harm.\\n\\n\\nBiometric categorization systems that infer sensitive attributes like race, political opinions, trade union membership, religious or philosophical beliefs, sex life, or sexual orientation (with limited exceptions for labeling or filtering lawfully acquired datasets and for law enforcement use)\\n\\n\\nSocial scoring systems, such as systems that evaluate or classify individuals or groups based on social behavior or personal traits, causing them harm.\\n\\n\\nAssessing the risk of an individual committing criminal offenses based solely on profiling or personality traits (with limited exceptions)\\n\\n\\nCompiling facial recognition databases through untargeted scraping of facial images from the internet or CCTV footage\\n\\n\\nInferring emotions in workplaces or educational institutions\\n\\n\\nReal-time remote biometric identification in public places for law enforcement (with certain exceptions).\\n\\n\\nHigh-Risk AI Systems\\nThe Act imposes strict obligations on systems that it has determined pose a substantial threat to health, safety, or the fundamental rights of individuals, which are categorized as High-Risk AI (HRAI). These include: a) systems that are safety components of a product subject to other EU laws , and b) specific use cases, such as for systems intended to determine access or admission to educational institutions, to recruit or select workers or monitor worker performance, to determine eligibility for public assistance, creditworthiness, assess eligibility and pricing for health insurance, among others.\\nHRAI systems must comply with rigorous regulatory obligations, such as establishing a risk management system to continuously evaluate risks and mitigation strategies throughout the lifecycle of an HRAI system, comprehensive data governance measures to test for and evaluate risks of bias, preparing detailed technical documentation before the system is placed on the market, and ongoing monitoring obligations.\\nMinimal or Minor-Risk AI Systems\\nOther AI systems that do not pose unacceptable or high-risks face only limited requirements, such as transparency obligations. For example, the Act specifies that individuals should be informed when they are interacting with an AI system like a chatbot, and that artificially manipulated images, audio, or video content need to be clearly labeled. Most AI systems on the market are likely to fall under this category.\\nGeneral Purpose AI (GPAI)\\nSpecial requirements apply to providers of general purpose AI models and systems, like OpenAI, which will be required to:\\n\\n\\nDevelop detailed technical documentation of the model and provide it to the AI Office upon request\\n\\n\\nCreate documentation for deployers who use the GPAI model to develop their own AI systems\\n\\n\\nImplement policies intended to respect EU copyright law\\n\\n\\nProvide a summary of the content used to train the GPAI model\\n\\n\\nIn addition, providers of GPAI models with high impact capabilities that are deemed to present “systemic risks” (e.g., models trained on a large amount of compute, technically defined as 10^25 FLOPs), will be required to:\\n\\n\\nPerform model evaluations to identify and mitigate systemic risks, and continuously assess and mitigate the risks presented\\n\\n\\nNotify the EU Commission of models that meet the criteria of this category\\n\\n\\nMonitor and report serious incidents\\n\\n\\nImplement appropriate cybersecurity measures for the model and its physical infrastructure\\n\\n\\nGPAI model providers will be able to rely on a code of practice to demonstrate compliance with the AI Act’s requirements. These codes of practice are likely to lay the groundwork for specific details for implementing these obligations, and we look forward to working with the EU AI Office as they are developed over the next 9 months.\\nNext Steps and How to Prepare for Compliance\\nOpenAI is committed to complying with the EU AI Act and we will be working closely with the new EU AI Office as the law is implemented. In the coming months, we will continue to prepare technical documentation and other guidance for downstream providers and deployers of our GPAI models, while advancing the security and safety of the models we provide in the European market and beyond.\\nIf your organization is trying to determine how to comply with the AI Act, you should first attempt to classify any AI systems in scope. Identify what GPAI and other AI systems you use, determine how they are classified, and consider what obligations flow from your use cases. You should also determine whether you are a provider or deployer with respect to any AI systems in scope. These issues can be complex so you should consult with legal counsel if you have questions.\\nOur research\\n\\nOverview\\nIndex\\n\\nLatest advancements\\n\\nOpenAI o1\\nOpenAI o1-mini\\nGPT-4\\nGPT-4o mini\\nDALL·E 3\\nSora\\n\\nChatGPT\\n\\nFor Everyone\\nFor Teams\\nFor Enterprises\\nChatGPT login(opens in a new window)\\nDownload\\n\\nAPI\\n\\nPlatform overview\\nPricing\\nDocumentation(opens in a new window)\\nAPI login(opens in a new window)\\n\\nExplore more\\n\\nOpenAI for business\\nStories\\n\\nSafety overview\\n\\nSafety overview\\n\\nCompany\\n\\nAbout us\\nNews\\nOur Charter\\nSecurity\\nResidency\\nCareers\\n\\nTerms & policies\\n\\nTerms of use\\nPrivacy policy\\nBrand guidelines\\nOther policies\\n\\nEnglish (US)\\nOpenAI © 2015–2025\\n(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)\\nEnglish (US)'}], 'response_time': 3.05})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana Belen\\AppData\\Local\\Temp\\ipykernel_9140\\2062640700.py:2: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = legal_search_tool(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to perform search. Error: KeyError('title')\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the main requirements of the EU AI Act for high-risk AI systems?\"\n",
    "results = legal_search_tool(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquí te presento una explicación del EU AI Act (Ley de Inteligencia Artificial de la Unión Europea) en español:\n",
      "\n",
      "El EU AI Act es una propuesta de regulación de la Unión Europea para abordar los riesgos y desafíos asociados con el desarrollo y uso de la inteligencia artificial (IA). Los principales puntos clave son:\n",
      "\n",
      "1. Ámbito de aplicación: La ley abarca todas las aplicaciones de IA, tanto públicas como privadas, que se desarrollen o utilicen en la UE.\n",
      "\n",
      "2. Clasificación de sistemas de IA: Se establece una clasificación de sistemas de IA en función del nivel de riesgo que conllevan:\n",
      "   - IA de riesgo inaceptable (prohibida)\n",
      "   - IA de alto riesgo (sujeta a requisitos obligatorios)\n",
      "   - IA de bajo o mínimo riesgo (sólo requiere transparencia)\n",
      "\n",
      "3. Requisitos para sistemas de IA de alto riesgo:\n",
      "   - Evaluación de riesgos y mitigación\n",
      "   - Documentación y trazabilidad\n",
      "   - Supervisión humana\n",
      "   - Robustez, precisión y seguridad\n",
      "\n",
      "4. Gobernanza y supervisión: Se crea un nuevo organismo europeo de supervisión de la IA.\n",
      "\n",
      "5. Sanciones: Se establecen multas de hasta el 6% del volumen de negocios anual por incumplimiento.\n",
      "\n",
      "En resumen, el EU AI Act busca establecer un marco regulatorio equilibrado que promueva la innovación tecnológica al tiempo que protege los derechos fundamentales y la seguridad de los ciudadanos europeos.\n"
     ]
    }
   ],
   "source": [
    "query = \"Hola, me llamo Ana. Me gustaria saber que es la EU AI Act.\"\n",
    "language = \"Spanish\"\n",
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = await app_anthropic.ainvoke({\"messages\": input_messages, \"language\": language}, config)\n",
    "print(output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple, List\n",
    "from langchain_core.messages import AIMessage\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_message(text: str) -> str:\n",
    "    \"\"\"Clean message content by removing ALL whitespace issues\"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "    # Remove ALL problematic whitespace\n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    text = ' '.join(text.split())  # Replace multiple spaces with single space\n",
    "    text = text.rstrip()  # Extra insurance against trailing whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola, me llamo Ana. Me gustaria saber que es la EU AI Act.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_message(\"     Hola, me llamo Ana. Me gustaria saber que es la EU AI Act.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def enhanced_chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    app_openai,\n",
    "    app_anthropic,\n",
    "    num_turns: int = 2,\n",
    "    max_tokens: int = 10000\n",
    ") -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "    metrics = {\"token_usage\": 0, \"cost\": 0}\n",
    "    \n",
    "    async def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str\n",
    "    ) -> str:\n",
    "        print(f\"\\nProcessing {expert_name} response...\")\n",
    "        \n",
    "        # Create a clean message\n",
    "        clean_content = clean_message(message_content)\n",
    "        \n",
    "        # Different message structure for each model, now with max_tokens\n",
    "        if expert_name == \"Legal Expert\":\n",
    "            messages = {\n",
    "                \"messages\": [HumanMessage(content=clean_content)], \n",
    "                \"language\": language,\n",
    "                \"max_tokens\": max_tokens  # Use the max_tokens parameter\n",
    "            }\n",
    "        else:\n",
    "            messages = {\n",
    "                \"messages\": [\n",
    "                    SystemMessage(content=\"You are a social media expert. Convert complex information into engaging, clear content.\"),\n",
    "                    HumanMessage(content=clean_content)\n",
    "                ],\n",
    "                \"language\": language,\n",
    "                \"max_tokens\": max_tokens  # Use the max_tokens parameter\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            output = await app.ainvoke(messages, config)\n",
    "            response = clean_message(output[\"messages\"][-1].content)\n",
    "            print(f\"{expert_name} responded: {response[:100]}...\")\n",
    "            \n",
    "            conversation_history.append({\n",
    "                \"role\": expert_name,\n",
    "                \"content\": response,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {expert_name} response: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    try:\n",
    "        current_query = clean_message(query)\n",
    "        \n",
    "        # Now use num_turns for multiple exchanges\n",
    "        for turn in range(num_turns):\n",
    "            print(f\"\\n=== Turn {turn + 1}/{num_turns} ===\")\n",
    "            \n",
    "            # Legal Expert Analysis\n",
    "            legal_response = process_model_response(\n",
    "                app_openai,\n",
    "                current_query,\n",
    "                \"Legal Expert\"\n",
    "            )\n",
    "            \n",
    "            # Social Media Expert Translation\n",
    "            social_prompt = (\n",
    "                \"Transform this legal explanation into engaging social media content. \"\n",
    "                \"Keep it clear and accurate, but make it more accessible and interesting \"\n",
    "                f\"for a general audience: {legal_response}\"\n",
    "            )\n",
    "            \n",
    "            social_response = process_model_response(\n",
    "                app_anthropic,\n",
    "                social_prompt,\n",
    "                \"Social Media Expert\"\n",
    "            )\n",
    "            \n",
    "            # Update query for next turn if there are more turns\n",
    "            if turn < num_turns - 1:\n",
    "                current_query = (\n",
    "                    \"Based on the previous responses, please provide additional insights \"\n",
    "                    \"or explore another aspect of the EU AI Act. \"\n",
    "                    f\"Previous legal response: {legal_response} \"\n",
    "                    f\"Previous social media response: {social_response}\"\n",
    "                )\n",
    "        \n",
    "        # Generate final summary\n",
    "        summary_prompt = (\n",
    "            \"Please provide a brief, clear summary of all the key points discussed \"\n",
    "            \"in our conversation about the EU AI Act.\"\n",
    "        )\n",
    "        \n",
    "        summary = process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during conversation: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coroutine object enhanced_chain_conversation at 0x000002064BE7F120>\n"
     ]
    }
   ],
   "source": [
    "# Example usage with specific turns and token limit\n",
    "result = enhanced_chain_conversation(\n",
    "    query=query,\n",
    "    language=language,\n",
    "    app_openai=app_openai,\n",
    "    app_anthropic=app_anthropic,\n",
    "    num_turns=3,  # Will do 3 rounds of exchanges\n",
    "    #max_tokens=800  # Limit response lengths\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    app_openai,\n",
    "    app_anthropic,\n",
    "    num_turns: int,\n",
    ") -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "        \n",
    "    async def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str,\n",
    "    ) -> str:\n",
    "        print(f\"\\nProcessing {expert_name} response...\")\n",
    "        \n",
    "        clean_content = clean_message(message_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Different message structure for each model\n",
    "        if expert_name == \"Legal Expert\":\n",
    "            messages = {\n",
    "                \"messages\": [HumanMessage(content=clean_content)],\n",
    "                \"language\": language\n",
    "            }\n",
    "        else:\n",
    "            # For Anthropic, only include system message when specified\n",
    "            message_list = []\n",
    "            if include_system:\n",
    "                message_list.append(\n",
    "                    SystemMessage(content=\"You are a social media expert. Convert complex information into engaging, clear content.\")\n",
    "                )\n",
    "            message_list.append(HumanMessage(content=clean_content))\n",
    "            messages = {\n",
    "                \"messages\": message_list,\n",
    "                \"language\": language\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            output = await app.ainvoke(messages, config)\n",
    "            response = clean_message(output[\"messages\"][-1].content)\n",
    "            print(f\"{expert_name} responded: {response[:100]}...\")\n",
    "            \n",
    "            conversation_history.append({\n",
    "                \"role\": expert_name,\n",
    "                \"content\": response,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {expert_name} response: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    try:\n",
    "        current_query = clean_message(query)\n",
    "        \n",
    "        for turn in range(num_turns):\n",
    "            print(f\"\\n=== Turn {turn + 1}/{num_turns} ===\")\n",
    "            \n",
    "            # Legal Expert Analysis\n",
    "            legal_response = await process_model_response(\n",
    "                app_openai,\n",
    "                current_query,\n",
    "                \"Legal Expert\"\n",
    "            )\n",
    "            \n",
    "            # Social Media Expert Translation\n",
    "            # Only include system message in first turn\n",
    "            social_prompt = (\n",
    "                \"Transform this legal explanation into engaging social media content \"\n",
    "                \"while maintaining accuracy and using appropriate language. \"\n",
    "                f\"Legal explanation: {legal_response}\"\n",
    "            )\n",
    "            \n",
    "            social_response = await process_model_response(\n",
    "                app_anthropic,\n",
    "                social_prompt,\n",
    "                \"Social Media Expert\",\n",
    "                include_system=(turn == 0)  # Only include system message in first turn\n",
    "            )\n",
    "            \n",
    "            # Update query for next turn\n",
    "            if turn < num_turns - 1:\n",
    "                current_query = clean_message(\n",
    "                    \"Based on the previous responses, please provide additional insights \"\n",
    "                    \"about a different aspect of the EU AI Act that hasn't been covered yet. \"\n",
    "                    f\"Previous legal response: {legal_response}\"\n",
    "                )\n",
    "        \n",
    "        # Generate final summary without system message\n",
    "        summary_prompt = clean_message(\n",
    "            \"Please provide a brief, clear summary of all the key points discussed \"\n",
    "            \"about the EU AI Act in our conversation.\"\n",
    "        )\n",
    "        \n",
    "        summary = await process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\",\n",
    "            include_system=False  # Don't include system message for summary\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during conversation: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Turn 1/3 ===\n",
      "\n",
      "Processing Legal Expert response...\n",
      "Legal Expert responded: Hola, Ana. La EU AI Act, conocida formalmente como la Ley de Inteligencia Artificial de la Unión Eur...\n",
      "\n",
      "Processing Social Media Expert response...\n",
      "Error in Social Media Expert response: Received multiple non-consecutive system messages.\n",
      "\n",
      "❌ Error during conversation: Received multiple non-consecutive system messages.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result = await enhanced_chain_conversation(\n",
    "    query=query,\n",
    "    language=language,\n",
    "    app_openai=app_openai,\n",
    "    app_anthropic=app_anthropic,\n",
    "    num_turns=3\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Query: ¿Qué es la EU AI Act y cómo afectará a las empresas?\n",
      "\n",
      "🔄 Processing conversation...\n",
      "\n",
      "\n",
      "=== Turn 1/3 ===\n",
      "\n",
      "Processing Legal Expert response...\n",
      "\n",
      "Processing Social Media Expert response...\n",
      "\n",
      "❌ Error during conversation: Received multiple non-consecutive system messages.\n",
      "❌ An error occurred during the conversation\n"
     ]
    }
   ],
   "source": [
    "async def enhanced_chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    app_openai,\n",
    "    app_anthropic,\n",
    "    num_turns: int = 2,\n",
    "    max_tokens: int = 1000\n",
    ") -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "    metrics = {\"token_usage\": 0, \"cost\": 0}\n",
    "    \n",
    "    async def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str\n",
    "    ) -> str:\n",
    "        print(f\"\\nProcessing {expert_name} response...\")\n",
    "        \n",
    "        # Clean input message\n",
    "        clean_content = clean_message(message_content)\n",
    "        \n",
    "        # Create message with cleaned content\n",
    "        message = HumanMessage(content=clean_content)\n",
    "        \n",
    "        # Get response from model\n",
    "        output = await app.ainvoke(\n",
    "            {\"messages\": [message], \"language\": language},\n",
    "            config\n",
    "        )\n",
    "        \n",
    "        if not output or \"messages\" not in output or not output[\"messages\"]:\n",
    "            raise ValueError(\"No valid response received from model\")\n",
    "        \n",
    "        # Clean the response content\n",
    "        response = clean_message(output[\"messages\"][-1].content)\n",
    "        \n",
    "        # Store in conversation history\n",
    "        conversation_history.append({\n",
    "            \"role\": expert_name,\n",
    "            \"content\": response,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    try:\n",
    "        # Clean initial query\n",
    "        current_query = clean_message(query)\n",
    "        \n",
    "        for turn in range(num_turns):\n",
    "            print(f\"\\n=== Turn {turn + 1}/{num_turns} ===\")\n",
    "            \n",
    "            # Legal Expert Analysis\n",
    "            legal_response = await process_model_response(\n",
    "                app_openai,\n",
    "                current_query,\n",
    "                \"Legal Expert\"\n",
    "            )\n",
    "            \n",
    "            # Social Media Expert Translation\n",
    "            social_prompt = clean_message(\n",
    "                f\"You are a social media expert. Please transform this legal explanation into engaging social media content \"\n",
    "                f\"while maintaining accuracy. Use {language} language. Legal explanation: {legal_response}\"\n",
    "            )\n",
    "            \n",
    "            social_response = await process_model_response(\n",
    "                app_anthropic,\n",
    "                social_prompt,\n",
    "                \"Social Media Expert\"\n",
    "            )\n",
    "            \n",
    "            # Update query for next turn if needed\n",
    "            if turn < num_turns - 1:\n",
    "                current_query = clean_message(\n",
    "                    f\"Based on these explanations, what additional aspects of the EU AI Act should we explore? \"\n",
    "                    f\"Previous legal response: {legal_response} \"\n",
    "                    f\"Previous social media response: {social_response}\"\n",
    "                )\n",
    "        \n",
    "        # Generate final summary\n",
    "        summary_prompt = clean_message(\n",
    "            f\"Please provide a brief summary in {language} of the key points discussed about the EU AI Act in this conversation.\"\n",
    "        )\n",
    "        \n",
    "        summary = await process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during conversation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "async def run_conversation():\n",
    "    query = \"¿Qué es la EU AI Act y cómo afectará a las empresas?\"\n",
    "    language = \"Spanish\"\n",
    "    global config\n",
    "    config = {\"configurable\": {\"thread_id\": \"test123\"}}\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(\"\\n🔄 Processing conversation...\\n\")\n",
    "    \n",
    "    result = await enhanced_chain_conversation(\n",
    "        query=query,\n",
    "        language=language,\n",
    "        app_openai=app_openai,\n",
    "        app_anthropic=app_anthropic,\n",
    "        num_turns=3\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n=== Conversation Summary ===\\n\")\n",
    "        print(f\"🎯 Original Query: {result['original_query']}\\n\")\n",
    "        \n",
    "        for entry in result['conversation']:\n",
    "            print(f\"\\n👤 {entry['role']}:\")\n",
    "            print(f\"{entry['content']}\\n\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        print(\"\\n📋 Final Summary:\")\n",
    "        print(f\"{result['summary']}\\n\")\n",
    "    else:\n",
    "        print(\"❌ An error occurred during the conversation\")\n",
    "\n",
    "# Execute\n",
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the conversation...\n",
      "\n",
      "📝 Query: ¿Qué es la EU AI Act y cómo afectará a las empresas?\n",
      "\n",
      "🔄 Processing conversation...\n",
      "\n",
      "\n",
      "=== Turn 1/3 ===\n",
      "\n",
      "Processing Legal Expert response...\n",
      "Legal Expert responded: La EU AI Act, formalmente conocida como el Reglamento sobre la Inteligencia Artificial de la Unión E...\n",
      "\n",
      "Processing Social Media Expert response...\n",
      "Error in Social Media Expert response: Received multiple non-consecutive system messages.\n",
      "\n",
      "❌ Error during conversation: Received multiple non-consecutive system messages.\n",
      "❌ An error occurred during the conversation\n",
      "Conversation completed!\n"
     ]
    }
   ],
   "source": [
    "def chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    app_openai,\n",
    "    app_anthropic,\n",
    "    num_turns: int = 2,\n",
    "    max_tokens: int = 1000\n",
    ") -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "    metrics = {\"token_usage\": 0, \"cost\": 0}\n",
    "    \n",
    "    def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str\n",
    "    ) -> str:\n",
    "        print(f\"\\nProcessing {expert_name} response...\")\n",
    "        \n",
    "        # Clean input message\n",
    "        clean_content = clean_message(message_content)\n",
    "        message = HumanMessage(content=clean_content)\n",
    "        \n",
    "        try:\n",
    "            # Use invoke instead of ainvoke\n",
    "            output = app.invoke(\n",
    "                {\"messages\": [message], \"language\": language},\n",
    "                config\n",
    "            )\n",
    "            \n",
    "            if not output or \"messages\" not in output or not output[\"messages\"]:\n",
    "                raise ValueError(\"No valid response received from model\")\n",
    "            \n",
    "            response = clean_message(output[\"messages\"][-1].content)\n",
    "            print(f\"{expert_name} responded: {response[:100]}...\")\n",
    "            \n",
    "            conversation_history.append({\n",
    "                \"role\": expert_name,\n",
    "                \"content\": response,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {expert_name} response: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    try:\n",
    "        current_query = clean_message(query)\n",
    "        \n",
    "        for turn in range(num_turns):\n",
    "            print(f\"\\n=== Turn {turn + 1}/{num_turns} ===\")\n",
    "            \n",
    "            # Legal Expert Analysis\n",
    "            legal_response = process_model_response(\n",
    "                app_openai,\n",
    "                current_query,\n",
    "                \"Legal Expert\"\n",
    "            )\n",
    "            \n",
    "            # Social Media Expert Translation\n",
    "            social_prompt = clean_message(\n",
    "                f\"You are a social media expert. Please transform this legal explanation into engaging social media content \"\n",
    "                f\"while maintaining accuracy. Use {language} language. Legal explanation: {legal_response}\"\n",
    "            )\n",
    "            \n",
    "            social_response = process_model_response(\n",
    "                app_anthropic,\n",
    "                social_prompt,\n",
    "                \"Social Media Expert\"\n",
    "            )\n",
    "            \n",
    "            # Update query for next turn if needed\n",
    "            if turn < num_turns - 1:\n",
    "                current_query = clean_message(\n",
    "                    f\"Based on these explanations, what additional aspects of the EU AI Act should we explore? \"\n",
    "                    f\"Previous legal response: {legal_response} \"\n",
    "                    f\"Previous social media response: {social_response}\"\n",
    "                )\n",
    "        \n",
    "        # Generate final summary\n",
    "        summary_prompt = clean_message(\n",
    "            f\"Please provide a brief summary in {language} of the key points discussed about the EU AI Act in this conversation.\"\n",
    "        )\n",
    "        \n",
    "        summary = process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during conversation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def run_conversation():\n",
    "    query = \"¿Qué es la EU AI Act y cómo afectará a las empresas?\"\n",
    "    language = \"Spanish\"\n",
    "    global config\n",
    "    config = {\"configurable\": {\"thread_id\": \"test123\"}}\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(\"\\n🔄 Processing conversation...\\n\")\n",
    "    \n",
    "    result = chain_conversation(\n",
    "        query=query,\n",
    "        language=language,\n",
    "        app_openai=app_openai,\n",
    "        app_anthropic=app_anthropic,\n",
    "        num_turns=3\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n=== Conversation Summary ===\\n\")\n",
    "        print(f\"🎯 Original Query: {result['original_query']}\\n\")\n",
    "        \n",
    "        for entry in result['conversation']:\n",
    "            print(f\"\\n👤 {entry['role']}:\")\n",
    "            print(f\"{entry['content']}\\n\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        print(\"\\n📋 Final Summary:\")\n",
    "        print(f\"{result['summary']}\\n\")\n",
    "    else:\n",
    "        print(\"❌ An error occurred during the conversation\")\n",
    "\n",
    "# Execute\n",
    "print(\"Starting the conversation...\")\n",
    "run_conversation()\n",
    "print(\"Conversation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def enhanced_chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    num_turns: int = 2,\n",
    "    max_tokens: int = 1000\n",
    ") -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "    metrics = {\"token_usage\": 0, \"cost\": 0}\n",
    "    \n",
    "    async def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str\n",
    "    ) -> str:\n",
    "        # Clean input message\n",
    "        clean_content = clean_message(message_content)\n",
    "        \n",
    "        # Create message with cleaned content\n",
    "        message = HumanMessage(content=clean_content)\n",
    "        \n",
    "        # Get response from model\n",
    "        output = await app.ainvoke(\n",
    "            {\"messages\": [message], \"language\": language},\n",
    "            config\n",
    "        )\n",
    "        \n",
    "        if not output or \"messages\" not in output or not output[\"messages\"]:\n",
    "            raise ValueError(\"No valid response received from model\")\n",
    "        \n",
    "        # Clean the response content\n",
    "        response = clean_message(output[\"messages\"][-1].content)\n",
    "        \n",
    "        # Store in conversation history\n",
    "        conversation_history.append({\n",
    "            \"role\": expert_name,\n",
    "            \"content\": response,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    try:\n",
    "        # Clean initial query\n",
    "        current_query = clean_message(query)\n",
    "        \n",
    "        for turn in range(num_turns):\n",
    "            # Legal Expert Analysis\n",
    "            legal_response = await process_model_response(\n",
    "                app_openai,\n",
    "                current_query,\n",
    "                \"Legal Expert\"\n",
    "            )\n",
    "            \n",
    "            # Social Media Expert Translation\n",
    "            social_prompt = clean_message(\n",
    "                f\"Transform this legal explanation into engaging social media content while maintaining accuracy: {legal_response}\"\n",
    "            )\n",
    "            \n",
    "            social_response = await process_model_response(\n",
    "                app_anthropic,\n",
    "                social_prompt,\n",
    "                \"Social Media Expert\"\n",
    "            )\n",
    "            \n",
    "            # Update query for next turn if needed\n",
    "            if turn < num_turns - 1:\n",
    "                current_query = clean_message(\n",
    "                    f\"Based on these explanations, what additional insights would be helpful? Legal: {legal_response} Social: {social_response}\"\n",
    "                )\n",
    "        \n",
    "        # Generate final summary\n",
    "        summary_prompt = clean_message(\n",
    "            \"Provide a brief summary of the key points discussed in this conversation.\"\n",
    "        )\n",
    "        \n",
    "        summary = await process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversation: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Sequence, Tuple, List\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "def clean_message(text: str) -> str:\n",
    "    \"\"\"Clean message content by removing excessive whitespace\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "async def enhanced_chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    app_openai, \n",
    "    app_anthropic,\n",
    "    config: dict,\n",
    "    num_turns: int = 2,\n",
    "    max_tokens: int = 1000,\n",
    "   ) -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "    metrics = {\"token_usage\": 0, \"cost\": 0}\n",
    "    \n",
    "    async def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str\n",
    "    ) -> str:\n",
    "        # Create a clean message\n",
    "        clean_content = clean_message(message_content)\n",
    "        messages = {\"messages\": [HumanMessage(content=clean_content)], \"language\": language}\n",
    "        \n",
    "        # Get response from model\n",
    "        output = await app.ainvoke(messages, config)\n",
    "        \n",
    "        if not output or \"messages\" not in output or not output[\"messages\"]:\n",
    "            raise ValueError(\"No valid response received from model\")\n",
    "            \n",
    "        response = clean_message(output[\"messages\"][-1].content)\n",
    "        \n",
    "        # Update metrics (if output contains token usage/cost information)\n",
    "        if \"token_usage\" in output:\n",
    "            metrics[\"token_usage\"] += output[\"token_usage\"]\n",
    "        if \"cost\" in output:\n",
    "            metrics[\"cost\"] += output[\"cost\"]\n",
    "        \n",
    "        # Store in conversation history\n",
    "        conversation_history.append({\n",
    "            \"role\": expert_name,\n",
    "            \"content\": response,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    try:\n",
    "        # Initial query\n",
    "        current_query = query\n",
    "        \n",
    "        for turn in range(num_turns):\n",
    "            # Legal Expert Analysis\n",
    "            legal_response = await process_model_response(\n",
    "                app_openai,\n",
    "                current_query,\n",
    "                \"Legal Expert\"\n",
    "            )\n",
    "            \n",
    "            # Social Media Expert Translation\n",
    "            social_prompt = clean_message(\n",
    "                f\"Transform this legal explanation into engaging, clear content \"\n",
    "                f\"that would work well on social media while maintaining accuracy: {legal_response}\"\n",
    "            )\n",
    "            \n",
    "            social_response = await process_model_response(\n",
    "                app_anthropic,\n",
    "                social_prompt,\n",
    "                \"Social Media Expert\"\n",
    "            )\n",
    "            \n",
    "            # Update query for next turn if needed\n",
    "            if turn < num_turns - 1:\n",
    "                current_query = clean_message(\n",
    "                    \"Based on both explanations above, what additional insights \"\n",
    "                    f\"or clarifications would be helpful? Legal response: {legal_response} \"\n",
    "                    f\"Social media response: {social_response}\"\n",
    "                )\n",
    "        \n",
    "        # Generate final summary\n",
    "        summary_prompt = clean_message(\n",
    "            \"Please provide a brief, clear summary of the key points discussed \"\n",
    "            \"in our conversation about this topic.\"\n",
    "        )\n",
    "        \n",
    "        summary = await process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversation: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_conversation():\n",
    "    query = \"¿Qué es la EU AI Act y cómo afectará a las empresas?\"\n",
    "    language = \"Spanish\"\n",
    "    global config\n",
    "    config = {\"configurable\": {\"thread_id\": \"test123\"}}\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(\"\\n🔄 Processing conversation...\\n\")\n",
    "    \n",
    "    result = await enhanced_chain_conversation(\n",
    "        query=query,\n",
    "        language=language,\n",
    "        app_openai=app_openai,  # Pass the OpenAI app\n",
    "        app_anthropic=app_anthropic  # Pass the Anthropic app\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n=== Conversation Summary ===\\n\")\n",
    "        print(f\"🎯 Original Query: {result['original_query']}\\n\")\n",
    "        \n",
    "        for entry in result['conversation']:\n",
    "            print(f\"\\n👤 {entry['role']}:\")\n",
    "            print(f\"{entry['content']}\\n\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        print(\"\\n📋 Final Summary:\")\n",
    "        print(f\"{result['summary']}\\n\")\n",
    "    else:\n",
    "        print(\"❌ An error occurred during the conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Query: ¿Qué es la EU AI Act y cómo afectará a las empresas?\n",
      "\n",
      "🔄 Processing conversation...\n",
      "\n",
      "Error during conversation: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages: at least one message is required'}}\n",
      "❌ An error occurred during the conversation\n"
     ]
    }
   ],
   "source": [
    "# Example usage with error handling and pretty printing\n",
    "async def run_conversation():\n",
    "    query = \"¿Qué es la EU AI Act y cómo afectará a las empresas?\"\n",
    "    language = \"Spanish\"\n",
    "    global config  # Make sure config is accessible\n",
    "    config = {\"configurable\": {\"thread_id\": \"test123\"}}\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(\"\\n🔄 Processing conversation...\\n\")\n",
    "    \n",
    "    result = await enhanced_chain_conversation(query, language)\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n=== Conversation Summary ===\\n\")\n",
    "        print(f\"🎯 Original Query: {result['original_query']}\\n\")\n",
    "        \n",
    "        for entry in result['conversation']:\n",
    "            print(f\"\\n👤 {entry['role']}:\")\n",
    "            print(f\"{entry['content']}\\n\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        print(\"\\n📋 Final Summary:\")\n",
    "        print(f\"{result['summary']}\\n\")\n",
    "    else:\n",
    "        print(\"❌ An error occurred during the conversation\")\n",
    "\n",
    "# Run the conversation\n",
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the conversation...\n",
      "\n",
      "📝 Query: ¿Qué es la EU AI Act y cómo afectará a las empresas?\n",
      "\n",
      "🔄 Processing conversation...\n",
      "\n",
      "\n",
      "Processing Legal Expert response...\n",
      "Legal Expert responded: La EU AI Act, que se refiere a la propuesta de Ley de Inteligencia Artificial de la Unión Europea, e...\n",
      "\n",
      "Processing Social Media Expert response...\n",
      "Social Media Expert responded: ¡Hola! Hoy vamos a hablar de un tema importante y emocionante: ¡La Ley de Inteligencia Artificial de...\n",
      "\n",
      "Processing Summary response...\n",
      "Error in Summary response: Received multiple non-consecutive system messages.\n",
      "\n",
      "❌ Error during conversation: Received multiple non-consecutive system messages.\n",
      "❌ An error occurred during the conversation\n",
      "Conversation completed!\n"
     ]
    }
   ],
   "source": [
    "async def enhanced_chain_conversation(\n",
    "    query: str,\n",
    "    language: str,\n",
    "    app_openai,\n",
    "    app_anthropic,\n",
    "    num_turns: int = 2,\n",
    "    max_tokens: int = 1000\n",
    ") -> dict:\n",
    "    \n",
    "    conversation_history = []\n",
    "    metrics = {\"token_usage\": 0, \"cost\": 0}\n",
    "    \n",
    "    async def process_model_response(\n",
    "        app, \n",
    "        message_content: str, \n",
    "        expert_name: str\n",
    "    ) -> str:\n",
    "        print(f\"\\nProcessing {expert_name} response...\")\n",
    "        \n",
    "        # Create a clean message\n",
    "        clean_content = clean_message(message_content)\n",
    "        \n",
    "        # Different message structure for each model\n",
    "        if expert_name == \"Legal Expert\":\n",
    "            messages = {\"messages\": [HumanMessage(content=clean_content)], \"language\": language}\n",
    "        else:\n",
    "            # For Anthropic, include a system message\n",
    "            messages = {\n",
    "                \"messages\": [\n",
    "                    SystemMessage(content=\"You are a social media expert. Convert complex information into engaging, clear content.\"),\n",
    "                    HumanMessage(content=clean_content)\n",
    "                ],\n",
    "                \"language\": language\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            output = await app.ainvoke(messages, config)\n",
    "            \n",
    "            if not output or \"messages\" not in output or not output[\"messages\"]:\n",
    "                raise ValueError(\"No valid response received from model\")\n",
    "            \n",
    "            response = clean_message(output[\"messages\"][-1].content)\n",
    "            print(f\"{expert_name} responded: {response[:100]}...\")\n",
    "            \n",
    "            conversation_history.append({\n",
    "                \"role\": expert_name,\n",
    "                \"content\": response,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {expert_name} response: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    try:\n",
    "        current_query = clean_message(query)\n",
    "        \n",
    "        # Legal Expert Analysis\n",
    "        legal_response = await process_model_response(\n",
    "            app_openai,\n",
    "            current_query,\n",
    "            \"Legal Expert\"\n",
    "        )\n",
    "        \n",
    "        # Social Media Expert Translation\n",
    "        social_prompt = (\n",
    "            \"Transform this legal explanation into engaging social media content. \"\n",
    "            \"Keep it clear and accurate, but make it more accessible and interesting \"\n",
    "            f\"for a general audience: {legal_response}\"\n",
    "        )\n",
    "        \n",
    "        social_response = await process_model_response(\n",
    "            app_anthropic,\n",
    "            social_prompt,\n",
    "            \"Social Media Expert\"\n",
    "        )\n",
    "        \n",
    "        # Generate final summary\n",
    "        summary_prompt = (\n",
    "            \"Please provide a brief, clear summary of the key points discussed \"\n",
    "            \"in our conversation about the EU AI Act.\"\n",
    "        )\n",
    "        \n",
    "        summary = await process_model_response(\n",
    "            app_anthropic,\n",
    "            summary_prompt,\n",
    "            \"Summary\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": query,\n",
    "            \"conversation\": conversation_history,\n",
    "            \"summary\": summary,\n",
    "            \"metrics\": metrics,\n",
    "            \"language\": language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during conversation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run the conversation\n",
    "async def run_conversation():\n",
    "    query = \"¿Qué es la EU AI Act y cómo afectará a las empresas?\"\n",
    "    language = \"Spanish\"\n",
    "    global config\n",
    "    config = {\"configurable\": {\"thread_id\": \"test123\"}}\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(\"\\n🔄 Processing conversation...\\n\")\n",
    "    \n",
    "    result = await enhanced_chain_conversation(\n",
    "        query=query,\n",
    "        language=language,\n",
    "        app_openai=app_openai,\n",
    "        app_anthropic=app_anthropic\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n=== Conversation Summary ===\\n\")\n",
    "        print(f\"🎯 Original Query: {result['original_query']}\\n\")\n",
    "        \n",
    "        for entry in result['conversation']:\n",
    "            print(f\"\\n👤 {entry['role']}:\")\n",
    "            print(f\"{entry['content']}\\n\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        print(\"\\n📋 Final Summary:\")\n",
    "        print(f\"{result['summary']}\\n\")\n",
    "    else:\n",
    "        print(\"❌ An error occurred during the conversation\")\n",
    "\n",
    "# Execute\n",
    "print(\"Starting the conversation...\")\n",
    "await run_conversation()\n",
    "print(\"Conversation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-wise-council-U8tERo2L-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
